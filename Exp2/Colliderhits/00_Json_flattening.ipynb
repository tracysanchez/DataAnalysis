{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0f35eb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Added cell to set Working Directory to your location\n",
    "import os\n",
    "import ast\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c4e6732",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Volumes/TwoTeras/0_Experiment_1/Eye_Tracking/Exploration_short/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b0a50b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Columns to keep from the raw data.\n",
    "Keep = [\"SubjectID\", \"Session\", \"SessionSubsection\",'timeStampDataPointStart', 'timeStampDataPointEnd', 'timeStampGetVerboseData','combinedGazeValidityBitmask','rayCastHitsCombinedEyes','eyePositionCombinedWorld.x', 'eyePositionCombinedWorld.y', 'eyePositionCombinedWorld.z','eyeDirectionCombinedWorld.y', \n",
    " 'eyeDirectionCombinedWorld.z', 'eyeDirectionCombinedLocal.x', 'eyeDirectionCombinedLocal.y', 'eyeDirectionCombinedLocal.z','hmdPosition.x', 'hmdPosition.y', 'hmdPosition.z', 'hmdDirectionForward.x', 'hmdDirectionForward.y', 'hmdDirectionForward.z', \n",
    " 'hmdRotation.x', 'hmdRotation.y', 'hmdRotation.z', 'hmdDirectionUp.x', 'hmdDirectionUp.y', 'hmdDirectionUp.z','playerBodyPosition.x', 'playerBodyPosition.y', 'playerBodyPosition.z', 'bodyTrackerPosition.x', 'bodyTrackerPosition.y', \n",
    " 'bodyTrackerPosition.z', 'bodyTrackerRotation.x', 'bodyTrackerRotation.y', 'bodyTrackerRotation.z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a0fb7e-af1d-4a8a-b6fa-7c01b0e6347e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0365', '0479', '1754', '2258', '2361', '2693', '3246', '3310', '3572', '3976', '4176', '4597', '4796', '4917', '5238', '5531', '5741', '6642', '7093', '7264', '7412', '7842', '8007', '8469', '8673', '8695', '9472', '9502', '9586', '9601']\n"
     ]
    }
   ],
   "source": [
    "data_path = os.getcwd()\n",
    "\n",
    "# Getting the Folder without hidden files in ascending order\n",
    "DATA_FOLDER = sorted([f for f in os.listdir(data_path) if not f.startswith('.')], key=str.lower)\n",
    "subIDs = []\n",
    "for sub in DATA_FOLDER:\n",
    "    if sub[0:4].isdigit():\n",
    "        subIDs.append(int(sub[0:4]))\n",
    "    else:\n",
    "        pass\n",
    "subIDs = np.unique(subIDs)\n",
    "#Sincesome participant IDs start with 0, we format them to show it in the string type\n",
    "IDstrings = ['{:04d}'.format(id) for id in subIDs]\n",
    "print(IDstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2015955e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0365/*.json', '0479/*.json', '1754/*.json', '2258/*.json', '2361/*.json', '2693/*.json', '3246/*.json', '3310/*.json', '3572/*.json', '3976/*.json', '4176/*.json', '4597/*.json', '4796/*.json', '4917/*.json', '5238/*.json', '5531/*.json', '5741/*.json', '6642/*.json', '7093/*.json', '7264/*.json', '7412/*.json', '7842/*.json', '8007/*.json', '8469/*.json', '8673/*.json', '8695/*.json', '9472/*.json', '9502/*.json', '9586/*.json', '9601/*.json']\n"
     ]
    }
   ],
   "source": [
    "#Create a generalized path for all json files per participant\n",
    "paths = [ID +  \"/*.json\" for ID in IDstrings]\n",
    "print(paths)\n",
    "#Create a sorted list of the paths to open de jsons\n",
    "Sorted_individual_jsons = sorted([filename for path in paths for filename in glob.glob(path)], key=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647a905",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 0365 Session 01 Section 2 has been normalized\n",
      "time is:  Thu May 11 16:52:16 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 01 Section 3 has been normalized\n",
      "time is:  Thu May 11 16:54:03 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 02 Section 1 has been normalized\n",
      "time is:  Thu May 11 16:56:03 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 02 Section 2 has been normalized\n",
      "time is:  Thu May 11 16:58:06 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 02 Section 3 has been normalized\n",
      "time is:  Thu May 11 17:00:05 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 03 Section 1 has been normalized\n",
      "time is:  Thu May 11 17:02:10 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 03 Section 2 has been normalized\n",
      "time is:  Thu May 11 17:04:14 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 03 Section 3 has been normalized\n",
      "time is:  Thu May 11 17:06:37 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 04 Section 1 has been normalized\n",
      "time is:  Thu May 11 17:08:43 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 04 Section 2 has been normalized\n",
      "time is:  Thu May 11 17:10:45 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 04 Section 3 has been normalized\n",
      "time is:  Thu May 11 17:13:07 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 01 Section 1 has been normalized\n",
      "time is:  Thu May 11 17:15:22 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 05 Section 2 has been normalized\n",
      "time is:  Thu May 11 17:17:35 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 05 Section 3 has been normalized\n",
      "time is:  Thu May 11 17:20:11 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0365 Session 05 Section 1 has been normalized\n",
      "time is:  Thu May 11 17:22:46 2023\n",
      "Combined\n",
      "Appended\n",
      "Saved\n",
      "Subject 0479 Session 01 Section 1 has been normalized\n",
      "time is:  Thu May 11 17:29:33 2023\n",
      "Combined\n",
      "Appended\n",
      "Subject 0479 Session 01 Section 2 has been normalized\n",
      "time is:  Thu May 11 17:31:30 2023\n"
     ]
    }
   ],
   "source": [
    "data_raw = pd.DataFrame()\n",
    "\n",
    "# read every file name in folder\n",
    "for path in paths:\n",
    "    for filename in glob.glob(path):\n",
    "        with open(filename, 'r') as file:\n",
    "            try:\n",
    "                # make json files parsable\n",
    "                data = \"[\" + file.read()\n",
    "                data = data[:len(data)] + \"]\"\n",
    "                raw = json.loads(data)\n",
    "            except:\n",
    "                print(\"reading did not work\")\n",
    "                \n",
    "\n",
    "            # Uneast the higher level of each file\n",
    "            currentDF_raw = pd.json_normalize(raw[0]['trials'][0]['dataPoints'])\n",
    "            print( \"Subject \" + str(filename[5:9]) + \" Session \" + str(filename[17:19]) +\" Section \" + str(filename[23:24]) + \" has been normalized\")\n",
    "            #Reduce columns to just necessary information\n",
    "            print('time is: ', time.ctime())\n",
    "\n",
    "            # insert participant id and session information from the file name\n",
    "            currentDF_raw.insert(0, \"SubjectID\", [int(filename[5:9])] * currentDF_raw.shape[0], True)\n",
    "            currentDF_raw.insert(1, \"Session\", [int(filename[17:19])] * currentDF_raw.shape[0], True)\n",
    "            currentDF_raw.insert(2, \"SessionSubsection\", [int(filename[23:24])] * currentDF_raw.shape[0], True)\n",
    "            \n",
    "            #Take out the unnecesary information\n",
    "            Reduced= currentDF_raw[Keep]\n",
    "\n",
    "            #Normalize the collider hits\n",
    "            Raycast = Reduced['rayCastHitsCombinedEyes'].explode().apply(pd.Series)\n",
    "            Combined = pd.concat([Reduced, Raycast], axis=1)\n",
    "            print('Combined')\n",
    "\n",
    "        data_raw = data_raw.append(Combined, ignore_index=True)\n",
    "        print('Appended')\n",
    "        currentDF_raw = pd.DataFrame()\n",
    "    data_raw.sort_values(by=[\"SubjectID\",\"Session\",\"SessionSubsection\"], inplace=True)\n",
    "    data_raw.to_csv(\"/Volumes/TwoTeras/0_Experiment_1/Eye_Tracking/Pre_processed/01_Indivuduals_Flat_smaller/\" + str(filename[5:9]) + \".csv\")\n",
    "    print('Saved')\n",
    "    data_raw = pd.DataFrame()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
