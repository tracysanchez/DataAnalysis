{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d91113f-7a7a-48f4-b342-92e564160582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f50de05-9776-48af-b1c3-65197d8f9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitmask_flag_change(Data_Frame, colname):\n",
    "    \"\"\" Creates a list of values that flag the change in validity of the Eyetracking data, \n",
    "    diferentiates between the beggining and enf of an invalid event. \n",
    "    \n",
    "Parameters\n",
    "-------------\n",
    "     \n",
    "     :dataframe(DataFrame): your data frame,\n",
    "     :colname(str): Name of the column that containts the validity mask \n",
    "returns \n",
    "----------\n",
    "\n",
    "    List of len DataFrame with values that mark changes on the validity column\n",
    "     \"\"\"\n",
    "    change_flag = [\"No_change\"] # initialize flag \n",
    "    for i in range(1, len(Data_Frame)):\n",
    "        if Data_Frame[colname][i] == Data_Frame[colname][i-1]: # compare each value with the previous value\n",
    "          change_flag.append(\"No_change\") \n",
    "        elif Data_Frame[colname][i] != Data_Frame[colname][i-1]:\n",
    "            if Data_Frame[colname][i] == 3:\n",
    "                  change_flag.append(\"Invalid_Section_Ends\")\n",
    "            elif Data_Frame[colname][i] == 0:\n",
    "                change_flag.append(\"Invalid_Section_Starts\")\n",
    "            else:\n",
    "                change_flag.append(\"ERROR\")\n",
    "    return change_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e9c72a-d1f7-4b76-b0d4-b8567af4d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the collider names are too detailed, here we create a dictionary with patterns to classify them into our categories of interest\n",
    "patterns = {'\\d{2}_Sa':'Passive_Agent', '\\d{2}_Cma':'Active_Agent', 'Building_\\d+': 'Building'}\n",
    "patterns.update(dict.fromkeys(['Castle-TaskBuilding_56','HighSilo-TaskBuilding_49', 'Windmill-TaskBuilding_10_1', 'Church_TaskBuilding_16'], 'Global_Landmark'))\n",
    "patterns.update(dict.fromkeys(['TaskBuilding_2','TaskBuilding_3', 'TaskBuilding_5', 'TaskBuilding_8', 'TaskBuilding_9', 'TaskBuilding_11', 'TaskBuilding_13', 'TaskBuilding_14', 'TaskBuilding_20', 'TaskBuilding_21', 'TaskBuilding_23','TaskBuilding_27', 'TaskBuilding_29', 'TaskBuilding_32', 'TaskBuilding_34',  'TaskBuilding_38', 'TaskBuilding_41', 'TaskBuilding_42', 'TaskBuilding_44', 'TaskBuilding_45', 'TaskBuilding_47', 'TaskBuilding_50', 'TaskBuilding_51', 'TaskBuilding_52', 'BasketballCourt_58', 'Construction_57', 'Graffity_02', 'Graffity_03', 'Graffity_05', 'Graffity_08', 'Graffity_09', 'Graffity_11', 'Graffity_13', 'Graffity_14', 'Graffity_20', 'Graffity_21', 'Graffity_23', 'Graffity_27', 'Graffity_29', 'Graffity_32', 'Graffity_34', 'Graffity_38', 'Graffity_41', 'Graffity_42', 'Graffity_44', 'Graffity_45', 'Graffity_47',  'Graffity_50', 'Graffity_51', 'Graffity_52'], 'TaskBuilding_Public'))\n",
    "patterns.update(dict.fromkeys(['TaskBuilding_1','TaskBuilding_4', 'TaskBuilding_6', 'TaskBuilding_7', 'TaskBuilding_12', 'TaskBuilding_15', 'TaskBuilding_17', 'TaskBuilding_18', 'TaskBuilding_19', 'TaskBuilding_22', 'TaskBuilding_24','TaskBuilding_25', 'TaskBuilding_26', 'TaskBuilding_28', 'TaskBuilding_30',  'TaskBuilding_31', 'TaskBuilding_33', 'TaskBuilding_35', 'TaskBuilding_36', 'TaskBuilding_37', 'TaskBuilding_39', 'TaskBuilding_40', 'TaskBuilding_43', 'TaskBuilding_48', 'TaskBuilding_54','TaskBuilding_55','Graffity_1','Graffity_4', 'Graffity_6', 'Graffity_7', 'Graffity_12', 'Graffity_15', 'Graffity_17', 'Graffity_18', 'Graffity_19', 'Graffity_22', 'Graffity_24','Graffity_25', 'Graffity_26', 'Graffity_28', 'Graffity_30',  'Graffity_31', 'Graffity_33', 'Graffity_35', 'Graffity_36', 'Graffity_37', 'Graffity_39', 'Graffity_40', 'Graffity_43', 'Graffity_48', 'Graffity_54', 'Graffity_55' ], 'TaskBuilding_Residential'))\n",
    "default_val = 'Background'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ccb28e0-a29b-4e47-aa74-0ace31892663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0479_2\n",
      "0479_3\n",
      "0479_5\n",
      "1754_1\n",
      "1754_2\n",
      "1754_3\n",
      "1754_4\n",
      "1754_5\n",
      "2258_1\n",
      "2258_2\n",
      "2258_3\n",
      "2258_4\n",
      "2258_5\n",
      "2361_2\n",
      "2361_3\n",
      "2361_4\n",
      "2361_5\n",
      "2693_1\n",
      "2693_2\n",
      "2693_3\n",
      "2693_4\n",
      "2693_5\n",
      "3246_1\n",
      "3246_2\n",
      "3246_3\n",
      "3246_5\n",
      "3310_1\n",
      "3310_2\n",
      "3310_3\n",
      "3310_4\n",
      "3310_5\n",
      "3572_1\n",
      "3572_2\n",
      "3572_3\n",
      "3572_4\n",
      "3976_1\n",
      "3976_2\n",
      "3976_3\n",
      "3976_4\n",
      "3976_5\n",
      "4176_1\n",
      "4176_2\n",
      "4176_3\n",
      "4176_4\n",
      "4176_5\n",
      "4796_1\n",
      "4796_2\n",
      "4796_3\n",
      "4796_4\n",
      "4796_5\n",
      "4917_1\n",
      "4917_2\n",
      "4917_3\n",
      "4917_4\n",
      "4917_5\n",
      "5238_1\n",
      "5238_2\n",
      "5238_3\n",
      "5238_4\n",
      "5531_1\n",
      "5531_3\n",
      "5531_4\n",
      "5531_5\n",
      "5741_1\n",
      "5741_2\n",
      "5741_3\n",
      "5741_4\n",
      "5741_5\n",
      "6642_1\n",
      "6642_2\n",
      "6642_3\n",
      "6642_4\n",
      "6642_5\n",
      "7093_1\n",
      "7093_2\n",
      "7093_3\n",
      "7093_4\n",
      "7093_5\n",
      "7264_1\n",
      "7264_2\n",
      "7264_3\n",
      "7264_4\n",
      "7264_5\n",
      "7412_1\n",
      "7412_2\n",
      "7412_3\n",
      "7412_4\n",
      "7412_5\n",
      "7842_1\n",
      "7842_2\n",
      "7842_3\n",
      "7842_4\n",
      "7842_5\n",
      "8007_1\n",
      "8007_2\n",
      "8007_3\n",
      "8007_4\n",
      "8007_5\n",
      "8469_1\n",
      "8469_2\n",
      "8469_3\n",
      "8469_4\n",
      "8469_5\n",
      "8673_1\n",
      "8673_2\n",
      "8673_3\n",
      "8673_4\n",
      "8673_5\n",
      "8695_2\n",
      "8695_3\n",
      "8695_4\n",
      "8695_5\n",
      "9472_1\n",
      "9472_2\n",
      "9472_3\n",
      "9472_4\n",
      "9472_5\n",
      "9502_1\n",
      "9502_2\n",
      "9502_3\n",
      "9502_5\n",
      "9601_1\n",
      "9601_2\n",
      "9601_3\n",
      "9601_4\n",
      "9601_5\n",
      "0479_1\n"
     ]
    }
   ],
   "source": [
    "path = \"/Volumes/SSD/00_Data_Processing/Pre_processed/03_Individuals_IndividualSessions\" \n",
    "\n",
    "  \n",
    "# csv files in the path\n",
    "files = glob.glob(path + \"/*.csv\")\n",
    "  \n",
    "# defining an empty list to store \n",
    "# content\n",
    "data_frame = pd.DataFrame()\n",
    "content = []\n",
    "  \n",
    "# checking all the csv files in the \n",
    "# specified path\n",
    "for filename in files:\n",
    "    \n",
    "    # reading content of csv file\n",
    "    # content.append(filename)\n",
    "    One_participant = pd.read_csv(filename)\n",
    "    One_participant.drop(['Unnamed: 0',\"level_0\", \"index\"],axis=1, inplace=True)\n",
    "    #Apply function that marks beggining and end of invalid sections\n",
    "    One_participant[\"Bitmask_flag\"] = bitmask_flag_change(One_participant, \"combinedGazeValidityBitmask\")\n",
    "    One_participant.reset_index(inplace=True)\n",
    "    # Get index of begging and end of invalid events\n",
    "    indexLastValid = One_participant[One_participant[\"Bitmask_flag\"] == \"Invalid_Section_Starts\"].index\n",
    "    indexLastInValid = One_participant[One_participant[\"Bitmask_flag\"] == \"Invalid_Section_Ends\"].index\n",
    "    # Get 20 rows prior to the beggining of the invalid event \n",
    "    indexLower = indexLastValid - 20\n",
    "    indexUpper = indexLastValid\n",
    "    # Since it's possible that the invalid event occured less than 20 rows from the beggining of the file\n",
    "    # we need to correct so that the highest possible index is the firs value in the file\n",
    "    indexLower_r = [0 if i < 0 else i for i in indexLower]\n",
    "    #Create a list with the most common element 200ms before the invalid section started\n",
    "    Elements_to_replace = [One_participant.iloc[down:up,20].mode().iloc[0] for down, up in zip(indexLower_r, indexUpper)]\n",
    "    #Create new column for interpolated events\n",
    "    One_participant[\"Interpolated_collider\"] = One_participant[\"hitObjectColliderName\"]\n",
    "    #Concat the row indexes that need replacement\n",
    "    ranges = list(zip(indexLastValid, indexLastInValid))\n",
    "    #Replace the invalid event with the mode of 20 events prior\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        One_participant.iloc[lower:upper,-2]  = Elements_to_replace[i]\n",
    "    # Here we look for the patterns contained in the dictionary and create the more general/informative variable Collider_Categorical\n",
    "    One_participant['Collider_Categorical'] = One_participant['Interpolated_collider'].apply(lambda x: next((val for key, val in patterns.items() if re.match(key, x)), default_val))\n",
    "    One_participant['Collider_Categorical']\n",
    "    # Replace coordinates and eucledian distances with Nans\n",
    "    One_participant.loc[One_participant['combinedGazeValidityBitmask'] == 0, ['hitPointOnObject_x', 'hitPointOnObject_y', 'hitPointOnObject_z', 'Eucledian_distance']] =  np.nan \n",
    "    #Saves an individual file per session per subject with out duplicates\n",
    "    One_participant.to_csv(f\"/Volumes/SSD/00_Data_Processing/Pre_processed/04_Interpolated/{filename[-10:-4]}.csv\", index=True)\n",
    "    print(filename[-10:-4])\n",
    "    indexLastValid = []\n",
    "    indexLastInValid = []\n",
    "    indexLower = []\n",
    "    indexUpper = []\n",
    "    content.append(One_participant)\n",
    "\n",
    "# converting content to data frame\n",
    "data_frame = pd.concat(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
