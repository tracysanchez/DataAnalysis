{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afd94f1-cb6e-4dae-bd36-5c75136f0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math \n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f99c711-2957-4402-ade1-24fcf56cbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: calculate MAD saccade\n",
    "def at_mad(angular_vel, th_0=200):\n",
    "    # defines the saccade threshold (code from Ashima)\n",
    "    threshs = []\n",
    "    while True:\n",
    "        # take th_0\n",
    "        threshs.append(th_0)\n",
    "        # get all angles smaller than this\n",
    "        angular_vel = angular_vel[angular_vel < th_0]\n",
    "\n",
    "        # MAD:\n",
    "        # take the median of all angles smaller than th_0\n",
    "        median = np.median(angular_vel)\n",
    "        # substract the median value\n",
    "        diff = np.sqrt((angular_vel - median) ** 2)\n",
    "        # get the median of these values\n",
    "        med_abs_deviation = np.median(diff)\n",
    "\n",
    "        # calcualte the next threshold with the median\n",
    "        # 1.486 used when assuming a normal distribution\n",
    "        th_1 = median + 3 * 1.486 * med_abs_deviation\n",
    "        # if the thresholds are too different, redo the while loop\n",
    "        if abs(th_0 - th_1) > 1:\n",
    "            th_0 = th_1\n",
    "        # else, set the final threshold to the current one, break the while loop and return values\n",
    "        else:\n",
    "            saccade_thresh = th_1\n",
    "            threshs.append(saccade_thresh)\n",
    "            break\n",
    "    return saccade_thresh, threshs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9d7528-d670-4d7e-9387-16cfcfba6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "One_participant = pd.read_csv(\"/Volumes/SSD/00_Data_Processing/Pre_processed/04_Interpolated/0479_2.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7112b5cf-9ba9-497c-aa97-0c67aeafd0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete = pd.read_csv(\"/Volumes/SSD/00_Data_Processing/Pre_processed/Complete_Data_AngularV.cvs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bcae62d-a64b-452a-a49a-608f19dc49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One= Complete[(Complete.SubjectID == 479) & (Complete.Session == 2)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f17489c-c397-4410-b17a-6038ed4df551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######## Debbies Algorithm ########\n",
    "\n",
    "for_eye = One_participant.copy()\n",
    "time = for_eye[\"timeStampDataPointEnd\"].tolist()\n",
    "\n",
    "## Calculate Angular velocities\n",
    "# get individual coordinates\n",
    "subj = list(zip( for_eye[\"eyePositionCombinedWorld.x\"],for_eye[\"eyePositionCombinedWorld.y\"],for_eye[\"eyePositionCombinedWorld.z\"]))\n",
    "hpoo = list(zip(for_eye[\"hitPointOnObject_x\"], for_eye[\"hitPointOnObject_y\"],for_eye[\"hitPointOnObject_z\"]))\n",
    "# v_gaze_vec: get difference in hpoo\n",
    "v_gaze_vec = list(zip(for_eye[\"hitPointOnObject_x\"].diff(), for_eye[\"hitPointOnObject_y\"].diff(),for_eye[\"hitPointOnObject_z\"].diff()))\n",
    "# get difference in time:\n",
    "ts = for_eye[\"timeStampDataPointEnd\"].diff().tolist()\n",
    "# gaze_vec(t) is a unit vector in the direction of the gaze (eye+head) in world coordinates\n",
    "g_vec = list(np.subtract(hpoo, subj))\n",
    "gaze_vec = [np.array(v) / np.linalg.norm(np.array(v)) for v in g_vec]\n",
    "# v_gaze_inplane: is a scalar indicating the velocity in world coordinates at the location that is gazed at orthogonal to the gaze axis.\n",
    "z1 = [np.dot(v_gaze_vec_i, gaze_vec_i) for v_gaze_vec_i, gaze_vec_i in zip(v_gaze_vec, gaze_vec)]\n",
    "# z = (<v_gaze_vec(t), gaze_vec(t)> * gaze_vec(t))\n",
    "z = [z1[element] * np.array(gaze_vec[element]) for element in range(len(z1))]\n",
    "# ||v_gaze_vec(t) - z||\n",
    "v_gaze_inplane = np.linalg.norm(np.array(v_gaze_vec) - z, axis=-1)\n",
    "#Eucledian distance between eye coordinates and hit on object\n",
    "sub_hpoo = np.linalg.norm(np.array(subj) - np.array(hpoo), axis=-1)\n",
    "# arctan2(v_gaze_inplane, sub_hpoo)\n",
    "w_gaze = np.arctan2(v_gaze_inplane, sub_hpoo).tolist()\n",
    "# Turn angle of radians into degrees over seconds \n",
    "w_gaze = [(w / ts[idx] * 180 / math.pi) for idx, w in enumerate(w_gaze)]\n",
    "# save df\n",
    "for_eye[\"combined_vel\"] = w_gaze\n",
    "\n",
    "### 10 second for threshold calculation starts here\n",
    "\n",
    "int_len = 10  # number of seconds of the interval\n",
    "time = for_eye[\"timeStampDataPointEnd\"].values\n",
    "start = [time[0]]\n",
    "end = []\n",
    "start_idx = [0]\n",
    "end_idx = []\n",
    "for t, ti in enumerate(time[1:], start=1):\n",
    "    if ti - start[-1] > int_len:\n",
    "        end.append(time[t - 1])\n",
    "        end_idx.append(t - 1)\n",
    "        start.append(ti)\n",
    "        start_idx.append(t)\n",
    "# add the last timepoint to end\n",
    "end.append(time[-1])\n",
    "end_idx.append(len(time))\n",
    "\n",
    "# save it as new df\n",
    "int_data = pd.DataFrame({\n",
    "    \"start\": start,\n",
    "    \"end\": end,\n",
    "    \"start_idx\": start_idx,\n",
    "    \"end_idx\": end_idx\n",
    "})\n",
    "\n",
    "combined_vel = for_eye[\"combined_vel\"]\n",
    "\n",
    "# to add the final thresholds to for each segement\n",
    "scct = []\n",
    "for s, srt in enumerate(int_data[\"start\"].values):\n",
    "    # get the slice of the combined velocity\n",
    "    angular_vel = combined_vel[start_idx[s] : end_idx[s]]\n",
    "    # use the at_mad function to caluclate the threshold\n",
    "    saccade_th, thres = at_mad(angular_vel)\n",
    "    if np.isnan(saccade_th):\n",
    "        scct.append(thres[0])\n",
    "    else:\n",
    "        # add it to scct\n",
    "        scct.append(saccade_th)\n",
    "\n",
    "# add it to int_data and save\n",
    "int_data[\"thresh\"] = scct\n",
    "\n",
    "ranges = list(zip(int_data.start_idx, int_data.end_idx))    \n",
    "# go through all time intervals repeat the threshold as often as the time interval is long\n",
    "for i, (lower, upper) in enumerate(ranges):\n",
    "    for_eye.loc[lower:upper,\"thresh\"]  = int_data[\"thresh\"][i]\n",
    "    \n",
    "# go through combined velocity and save all that are bigger than the threshold\n",
    "    # Everywhere  where there is Nans that is a saccade meaning this are the cells that are really fast OR ####### we had nan on the combined velocity #######\n",
    "\n",
    "for_eye[\"isFix\"] = np.where(for_eye['combined_vel'] < for_eye[\"thresh\"], for_eye['combined_vel'], np.nan)\n",
    " ### reset for following parts\n",
    "    # specify the variables you want to delete in a list\n",
    "    \n",
    "to_delete = [int_data, start, end, start_idx, end_idx]\n",
    "\n",
    "# delete the variables using a loop\n",
    "for Object in to_delete:\n",
    "    del Object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dae8bfff-475b-4f52-9766-d30c4fead1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.07 ms ± 101 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for_eye.reset_index(inplace=True, drop=True)\n",
    "\n",
    "min_sacc_dur = 0.02  # min sacc duration\n",
    "min_gaze_dur = 0.04  # min gaze duration (Ashima uses 0.05)\n",
    "time = for_eye.timeStampDataPointEnd.values\n",
    "index = for_eye.index.tolist()  # index of df for easier use\n",
    "start_time = time[0]  # update for each change\n",
    "start_idx = index[0]  # will be updated each event and used to add to the lists\n",
    "\n",
    "# to save:\n",
    "isFix = []\n",
    "combined_vel = []\n",
    "\n",
    "# if the first sample does not have any data\n",
    "if pd.isna(for_eye.loc[0, \"combined_vel\"]) and not pd.isna(for_eye.loc[1, \"combined_vel\"]):\n",
    "    start_time = time[1]   # update for each change\n",
    "    start_idx = index[1]  # will be updated each event and used to add to the lists\n",
    "    isFix = [np.nan]\n",
    "    combined_vel = [np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12853d4a-806f-4c61-8d60-46059de12a22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Can only index by location with a [{self._valid_types}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can only index by location with a [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6bed26825ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# if the first sample does not have any data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfor_eye\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"combined_vel\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfor_eye\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"combined_vel\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# update for each change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mstart_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# will be updated each event and used to add to the lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1450\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1451\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    726\u001b[0m                     \u001b[0;34m\"Location based indexing can only have \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                     \u001b[0;34mf\"[{self._valid_types}] types\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "min_sacc_dur = 0.02  # min sacc duration\n",
    "min_gaze_dur = 0.04  # min gaze duration (Ashima uses 0.05)\n",
    "time = for_eye.timeStampDataPointEnd.values\n",
    "n_rows = for_eye.shape[0]  # number of rows in the DataFrame\n",
    "\n",
    "# to save:\n",
    "isFix = [np.nan] * n_rows\n",
    "combined_vel = [np.nan] * n_rows\n",
    "\n",
    "# if the first sample does not have any data\n",
    "if pd.isna(for_eye.iloc[0, \"combined_vel\"]) and not pd.isna(for_eye.iloc[1, \"combined_vel\"]):\n",
    "    start_time = time[1]   # update for each change\n",
    "    start_idx = 1  # will be updated each event and used to add to the lists\n",
    "else:\n",
    "    start_time = time[0]\n",
    "    start_idx = 0\n",
    "\n",
    "for i in range(n_rows):\n",
    "    if pd.isna(for_eye.iloc[i, \"combined_vel\"]):\n",
    "        isFix[i] = np.nan\n",
    "        combined_vel[i] = np.nan\n",
    "    else:\n",
    "        if time[i] - start_time >= min_gaze_dur:\n",
    "            if i - start_idx == 1:\n",
    "                isFix[start_idx] = False\n",
    "            else:\n",
    "                isFix[start_idx:i] = True\n",
    "            combined_vel[start_idx:i] = for_eye.iloc[start_idx:i, \"combined_vel\"].mean()\n",
    "            start_time = time[i]\n",
    "            start_idx = i\n",
    "\n",
    "# if the last sample is part of a fixation\n",
    "if isFix[-1] == np.nan:\n",
    "    if n_rows - start_idx == 1:\n",
    "        isFix[start_idx] = False\n",
    "    else:\n",
    "        isFix[start_idx:] = True\n",
    "    combined_vel[start_idx:] = for_eye.iloc[start_idx:, \"combined_vel\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09e229-ef97-4f20-ba10-3aea40577546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa6bff-111e-4c24-b5ca-4a1b2ca8b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pd.isna(for_eye.loc[0, \"combined_vel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd094e3-0878-479c-b17d-8ee2bc830e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit math.isnan(for_eye.iloc[0][\"combined_vel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f9e74-2423-4294-8b6d-36719d4c1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "math.isnan(for_eye.iloc[0][\"combined_vel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a1f25-730e-426f-a358-b69d8ef5db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(for_eye.loc[0, \"combined_vel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9f338-d895-473e-ba67-6ee8f0475d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye.loc[2, 'isFix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0db96-e09a-4b5f-8422-528f2d9fb912",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye[\"CheckisFix\"] = for_eye[\"isFix\"] == for_eye['isFixi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e0f4b-a224-41c1-91c9-c301faaf5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.DataFrame(combined_vel == for_eye[\"combined_vel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff666e2-2b5f-4e36-8581-9989b0e242da",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.DataFrame(combined_vel != for_eye[\"combined_vel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e1831-299c-473c-b2ed-d03bb9f860d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(av)\n",
    "len(av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59200330-25b6-4c16-8707-dcb1db289fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8577521-8786-4bff-89e4-6bb044297530",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7bbae-b05b-47be-aaad-53d33d35e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye[\"FIXICHECK\"] = for_eye['fixi'] != for_eye[\"isFix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279e83c-2e7a-4547-9fdc-9aeed65c01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "com = pd.DataFrame(av == avi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c82dd6-35df-419e-8e20-6a870bc70aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye[\"FIXICHECK\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2bdcb-bfd7-4ed6-8409-3ebe83dcefc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show = for_eye[for_eye.FIXICHECK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb06fe0a-9106-405b-aca8-f75813e44d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d7d74-b79f-49d9-bd3f-2ca32483899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, (lower,upper) in enumerate(ranges):\n",
    "    avi = for_eye.loc[lower:upper, \"combined_vel\"].values\n",
    "    fixi = [item if item < int_data[\"thresh\"][i] else np.nan for item in avi]\n",
    "    for_eye.loc[lower:upper,\"isFixi\"]  = for_eye.loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41410dc-80ec-465f-869d-49438344b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91403839-0738-4fd9-b2d1-a5c8f93e28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fixi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0567621-59c5-4d23-b950-de3cf8666ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye['fixi'] = np.where(for_eye['combined_vel'] < for_eye[\"thresh\"], for_eye['combined_vel'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd85bce-ef1b-4255-9fbc-91f36426d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye['fixi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c0731-957d-4f82-8a41-dd05077a0c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye-tracking\n",
    "thres = int_data[\"thresh\"].values\n",
    "combined_vel = for_eye[\"combined_vel\"].values\n",
    "\n",
    "# define list where the fixations will be added too\n",
    "is_fix = [np.nan] * len(combined_vel)\n",
    "start = int_data[\"start_idx\"].tolist()\n",
    "end = int_data[\"end_idx\"].tolist()\n",
    "\n",
    "# eye-tracking\n",
    "thres = int_data[\"thresh\"].tolist()\n",
    "combined_vel = for_eye[\"combined_vel\"].tolist()\n",
    "for i in range(len(start)):\n",
    "    av = combined_vel[start[i] : end[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95420d5b-566e-41eb-871a-ffc57a9059e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ffc61-9c1b-41aa-8b80-80c5c809e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b189e5a-2ed4-4a23-813d-b656f7e04673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, (lower, upper) in enumerate(ranges):\n",
    "    for_eye.loc[lower:upper,\"is-FIXI\"]  = int_data[\"thresh\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f59c59-1494-4463-bdda-88f8dce63105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye-tracking\n",
    "thres = int_data[\"thresh\"].values\n",
    "combined_vel = for_eye[\"combined_vel\"].values\n",
    "\n",
    "# define list where the fixations will be added too\n",
    "is_fix = [np.nan] * len(combined_vel)\n",
    "start = int_data[\"start_idx\"].tolist()\n",
    "end = int_data[\"end_idx\"].tolist()\n",
    "\n",
    "# eye-tracking\n",
    "thres = int_data[\"thresh\"].tolist()\n",
    "combined_vel = for_eye[\"combined_vel\"].tolist()\n",
    "\n",
    "\n",
    "for i in range(len(start)):\n",
    "    av = combined_vel[start[i] : end[i]]\n",
    "    # go through combined velocity and save all that are bigger than the threshold\n",
    "    fix = [ti if ti < thres[i] else np.nan for ti in av]\n",
    "    is_fix[start[i] : end[i]] = fix\n",
    "for_eye[\"isFix\"] = is_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf078f43-877e-4a0d-93e4-6c07c39ad8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "######## Debbies Algorithm ########\n",
    "\n",
    "for_eye = One_participant.copy()\n",
    "\n",
    "time = for_eye[\"timeStampDataPointEnd\"].tolist()\n",
    "# get individual coordinates\n",
    "subj = list(zip( for_eye[\"eyePositionCombinedWorld.x\"],for_eye[\"eyePositionCombinedWorld.y\"],for_eye[\"eyePositionCombinedWorld.z\"]))\n",
    "hpoo = list(zip(for_eye[\"hitPointOnObject_x\"], for_eye[\"hitPointOnObject_y\"],for_eye[\"hitPointOnObject_z\"]))\n",
    "\n",
    "# v_gaze_vec: get difference in hpoo\n",
    "v_vX = for_eye[\"hitPointOnObject_x\"].diff()\n",
    "v_vY = for_eye[\"hitPointOnObject_y\"].diff()\n",
    "v_vZ = for_eye[\"hitPointOnObject_z\"].diff()\n",
    "\n",
    "\n",
    "# get difference in time:\n",
    "ts = pd.DataFrame(time).apply(lambda x: x.diff())[0].tolist()\n",
    "v_gaze_vec = list(zip(v_vX, v_vY, v_vZ))\n",
    "\n",
    "# gaze_vec(t) is a unit vector in the direction of the gaze (eye+head) in world coordinates\n",
    "g_vec = [np.array(hpoo[v] - np.array(subj[v])) for v in range(len(subj))]\n",
    "gaze_vec = [np.array(v) / np.linalg.norm(np.array(v)) for v in g_vec]\n",
    "\n",
    "\n",
    "# v_gaze_inplane: is a scalar indicating the velocity in world coordinates at the location that is gazed at orthogonal to the gaze axis.\n",
    "# v_gaze_inplane(t) = ||v_gaze_vec(t) - (<v_gaze_vec(t), gaze_vec(t)> * gaze_vec(t))||:\n",
    "# z1 = (<v_gaze_vec(t), gaze_vec(t)>)\n",
    "z1 = [np.array(v_gaze_vec[t]).dot(np.array(gaze_vec[t]))\n",
    "        for t in range(len(v_vX))]\n",
    "\n",
    "# z = (<v_gaze_vec(t), gaze_vec(t)> * gaze_vec(t))\n",
    "z = [z1[t] * np.array(gaze_vec[t]) for t in range(len(v_vX))]\n",
    "\n",
    "# ||v_gaze_vec(t) - z||\n",
    "v_gaze_inplane = [np.linalg.norm((np.array(v_gaze_vec[t]) - z[t]).tolist())\n",
    "        for t in range(len(v_gaze_vec))\n",
    "                 ]\n",
    "# w_gaze(t) = arctan2(||subject_vec(t) - hpoo_vec(t)||, v_gaze_inplane)\n",
    "\n",
    "# sub_hpoo = ||subject_vec(t) - hpoo_vec(t)||\n",
    "sub_hpoo = [np.linalg.norm(np.array(subj[t]) - np.array(hpoo[t]))\n",
    "        for t in range(len(hpoo))]\n",
    "\n",
    "# arctan2(v_gaze_inplane, sub_hpoo)\n",
    "w_gaze = np.arctan2(v_gaze_inplane, sub_hpoo).tolist()\n",
    "\n",
    "# turn angle of radians into degrees\n",
    "#w_gaze = [np.rad2deg(value) for value in w_gaze]\n",
    "w_gaze = [(w / ts[idx] * 180 / math.pi) for idx, w in enumerate(w_gaze)]\n",
    "# save df\n",
    "for_eye[\"combined_vel\"] = w_gaze\n",
    "### 10 second starts here \n",
    "int_len = 10  # number of seconds of the interval\n",
    "\n",
    "time = for_eye[\"timeStampDataPointEnd\"].tolist()\n",
    "start = []\n",
    "end = []\n",
    "start_idx = []\n",
    "end_idx = []\n",
    "for t, ti in enumerate(time):\n",
    "    if ti == time[0]:\n",
    "        start.append(ti)\n",
    "        start_idx.append(t)\n",
    "    if ti - start[-1] > int_len:\n",
    "        # if the current timepoint is more than int_len away from start, set it to new start\n",
    "        start.append(ti)\n",
    "        start_idx.append(t)\n",
    "        # and set end to the timepoint before that\n",
    "        end.append(time[t - 1])\n",
    "        end_idx.append(t - 1)\n",
    "# add the last timepoint to end\n",
    "# (there is a very slim chance that the last start and end are the same timepoint --> might cause errors)\n",
    "end.append(time[-1])\n",
    "end_idx.append(len(time))\n",
    "\n",
    "# save it as new df\n",
    "int_data = list(zip(start, end, start_idx, end_idx))\n",
    "int_data = pd.DataFrame(\n",
    "    int_data, columns=[\"start\", \"end\", \"start_idx\", \"end_idx\"]\n",
    ")\n",
    "\n",
    "combined_vel = for_eye[\"combined_vel\"]\n",
    "\n",
    "# to shorten the slicing in the next for loop\n",
    "start_idx = int_data[\"start_idx\"].tolist()\n",
    "end_idx = int_data[\"end_idx\"].tolist()\n",
    "\n",
    "# to add the final thresholds to for each segement\n",
    "scct = []\n",
    "for s, srt in enumerate(int_data[\"start\"].tolist()):\n",
    "    # get the slice of the combined velocity\n",
    "    angular_vel = combined_vel[start_idx[s] : end_idx[s]]\n",
    "    # use the at_mad function to caluclate the threshold\n",
    "    saccade_th, thres = at_mad(angular_vel)\n",
    "    if np.isnan(saccade_th):\n",
    "        scct.append(thres[0])\n",
    "    else:\n",
    "        # add it to scct\n",
    "        scct.append(saccade_th)\n",
    "\n",
    "# add it to int_data and save\n",
    "int_data[\"thresh\"] = scct\n",
    "int_data = pd.DataFrame(int_data)\n",
    "time = for_eye.timeStampDataPointEnd.tolist()\n",
    "start_idx = int_data[\"start_idx\"].tolist()\n",
    "end_idx = int_data[\"end_idx\"].tolist()\n",
    "thr = int_data[\"thresh\"].tolist()\n",
    "\n",
    "# go through all time intervals\n",
    "thresh = [0.0] * len(time)\n",
    "for s, srt in enumerate(int_data[\"start\"].tolist()):\n",
    "    # repeat the threshold as often as the time interval is long\n",
    "    thresh = (\n",
    "        thresh[: start_idx[s]]\n",
    "        + [thr[s]] * len(time[start_idx[s] : end_idx[s]])\n",
    "        + thresh[end_idx[s]:]\n",
    "    )\n",
    "\n",
    "# add the two lists (ht & et) to for_eye df\n",
    "for_eye[\"thresh\"] = thresh\n",
    "\n",
    "# save for_eye df\n",
    "for_eye = pd.DataFrame(for_eye)\n",
    "\n",
    "start = int_data[\"start_idx\"].tolist()\n",
    "end = int_data[\"end_idx\"].tolist()\n",
    "\n",
    "# eye-tracking\n",
    "thres = int_data[\"thresh\"].tolist()\n",
    "combined_vel = for_eye[\"combined_vel\"].tolist()\n",
    "\n",
    "# define list where the fixations will be added too\n",
    "is_fix = [np.nan] * len(combined_vel)\n",
    "\n",
    "for i in range(len(start)):\n",
    "    av = combined_vel[start[i] : end[i]]\n",
    "    # go through combined velocity and save all that are bigger than the threshold\n",
    "    fix = [ti if ti < thres[i] else np.nan for ti in av]\n",
    "    is_fix[start[i] : end[i]] = fix\n",
    "\n",
    "# save\n",
    "for_eye[\"isFix\"] = is_fix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb8819-9e85-4032-86d3-12341cc80492",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = list(zip(int_data.start_idx, int_data.end_idx))\n",
    "#Replace the invalid event with the mode of 20 events prior\n",
    "for i, (lower, upper) in enumerate(ranges):\n",
    "    for_eye.loc[lower:upper,\"THRESHI\"]  = int_data[\"thresh\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d78f0-4f53-4712-ab43-a1192375f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ffbee4-a66f-4f09-8066-a9dfe3cc6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f9fe7f-7319-45f3-aa8e-581ce34c1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e8e7d-bd40-4da0-b038-b9761380040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "New = for_eye[\"combined_vel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9caf4f-34b4-4770-927a-9161a4ede9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695689c-5580-4932-98fd-fa08a42a0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Old = One[\"combined_vel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d77f67-4116-4afe-b0b3-1c3c9af44b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.scatter(New, Old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142ad73-429c-4309-ab67-6392165ccb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "corr, _ = spearmanr(New, Old, nan_policy='omit')\n",
    "print('Spearmans correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae71043-0552-45a1-9c20-7a939f3d637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10 second starts here \n",
    "int_len = 10  # number of seconds of the interval\n",
    "time = for_eye[\"timeStampDataPointEnd\"].values\n",
    "start = []\n",
    "end = []\n",
    "start_idx = []\n",
    "end_idx = []\n",
    "for t, ti in enumerate(time):\n",
    "    if ti == time[0]:\n",
    "        start.append(ti)\n",
    "        start_idx.append(t)\n",
    "    if ti - start[-1] > int_len:\n",
    "        # if the current timepoint is more than int_len away from start, set it to new start\n",
    "        start.append(ti)\n",
    "        start_idx.append(t)\n",
    "        # and set end to the timepoint before that\n",
    "        end.append(time[t - 1])\n",
    "        end_idx.append(t - 1)\n",
    "# add the last timepoint to end\n",
    "# (there is a very slim chance that the last start and end are the same timepoint --> might cause errors)\n",
    "end.append(time[-1])\n",
    "end_idx.append(len(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86c5fd-fe0a-4bb5-9da2-c97bd9417a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye.Continuous_Time.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df33980-8a5e-4468-b728-3dd247b1c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "for_eye[\"datetime_objects\"] = [datetime.datetime.utcfromtimestamp(timestamp) for timestamp in for_eye[\"timeStampDataPointEnd\"]]\n",
    "df_resampled = for_eye.resample('10S', on='datetime_objects').first()\n",
    "# Get the index of the resampled DataFrame\n",
    "resampled_index = df_resampled.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9b2a1-b6d0-4aa9-9383-6451b041237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled[\"saccade_thi\"], df_resampled[\"thresi\"] = for_eye[\"combined_vel\"].rolling('10s').apply(at_mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9da493-6993-4f6f-a0ae-fd44961cc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled[\"saccade_thi\"], df_resampled[\"thresi\"] = at_mad(df_resampled.combined_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3a349-f5bd-44b7-b726-7e989f486278",
   "metadata": {},
   "outputs": [],
   "source": [
    "saccade_thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c7975-753e-4c24-aebb-9cebf6ee7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ee26f-3d06-4a0b-99de-45b00cf1664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f2c6d-01d1-4a10-8081-ebdf0aa95900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "for_eye[\"datetime_objects\"] = [datetime.datetime.utcfromtimestamp(timestamp) for timestamp in for_eye[\"timeStampDataPointEnd\"]]\n",
    "datetime.datetime.utcfromtimestamp(for_eye.loc[1,\"timeStampDataPointEnd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769973a9-513d-44b5-96e2-7656a346d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye[\"time-time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ac722-434b-4931-85c0-207e67138842",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye[\"Continuous_Time\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441a8dc-6c93-4e97-885b-81b527eda310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to shorten the slicing in the next for loop\n",
    "start_idx = int_data[\"start_idx\"].values\n",
    "end_idx = int_data[\"end_idx\"].values\n",
    "\n",
    "# Vectorize calculation of angular velocity\n",
    "angular_veli = np.array([combined_vel[start:end] for start, end in zip(start_idx, end_idx)])\n",
    "\n",
    "# Calculate saccade thresholds for all segments at once\n",
    "saccade_th, thres = at_mad(angular_vel)\n",
    "\n",
    "# Replace NaN values with corresponding threshold from thres array\n",
    "scct = []\n",
    "scct.append(np.nan_to_num(thres)[0] if np.isnan(saccade_th) else saccade_th)\n",
    "\n",
    "# Assign saccade thresholds to int_data DataFrame\n",
    "int_data[\"threshi\"] = scct\n",
    "\n",
    "# Create a list of thresholds for each timestamp\n",
    "time = for_eye.timeStampDataPointEnd.values\n",
    "thresh = np.zeros(len(time))\n",
    "for s, (start, end, th) in enumerate(zip(start_idx, end_idx, saccade_thi)):\n",
    "    threshi[start:end] = th\n",
    "\n",
    "# Add threshold column to for_eye DataFrame\n",
    "for_eye[\"threshi\"] = threshi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff3a7e-dfe8-4a45-99dc-c03767ef99a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scct = [at_mad(combined_vel[start_idx[s] : end_idx[s]])[0] if not np.isnan(at_mad(combined_vel[start_idx[s] : end_idx[s]])[0]) else at_mad(combined_vel[start_idx[s] : end_idx[s]])[1][0] for s, start in enumerate(int_data[\"start\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8357ec-17b9-4680-9307-a2991d3877d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data[\"threshi\"] =  scct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a35793-eec6-43b8-b3cc-24f4e46efdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5de959-bec3-4402-9b54-7b572b7d6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(angular_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92021d9a-62ef-466c-86f2-49fabd3072b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(angular_veli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fbf623-8fcb-479f-9c22-a542851960d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idxi[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e58d8-35d9-4398-a362-20444f185550",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f17cce-ef6f-4f18-84cb-0f8a3e2fa911",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828f718-ffe6-4559-9c13-184328e42f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "INTERVAL_LENGTH = 10  # number of seconds of the interval\n",
    "time = for_eye[\"timeStampDataPointEnd\"].values\n",
    "start = []\n",
    "end = []\n",
    "start_idx = []\n",
    "end_idx = []\n",
    "for t, ti in enumerate(time):\n",
    "    if ti == time[0]:\n",
    "        start.append(ti)\n",
    "        start_idx.append(t)\n",
    "    if ti - start[-1] > INTERVAL_LENGTH:\n",
    "        # if the current timepoint is more than INTERVAL_LENGTH away from start, set it to new start\n",
    "        start.append(ti)\n",
    "        start_idx.append(t)\n",
    "        # and set end to the timepoint before that\n",
    "        end.append(time[t - 1])\n",
    "        end_idx.append(t - 1)\n",
    "# add the last timepoint to end\n",
    "end.append(time[-1])\n",
    "end_idx.append(len(time))\n",
    "\n",
    "# save it as new df\n",
    "int_data = {\n",
    "    \"start\": start,\n",
    "    \"end\": end,\n",
    "    \"start_idx\": np.array(start_idx),\n",
    "    \"end_idx\": np.array(end_idx),\n",
    "}\n",
    "int_data = pd.DataFrame(int_data)\n",
    "\n",
    "combined_vel = for_eye[\"combined_vel\"]\n",
    "\n",
    "# to shorten the slicing in the next for loop\n",
    "start_idx = int_data[\"start_idx\"].tolist()\n",
    "end_idx = int_data[\"end_idx\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ca750-9499-45f2-8a23-4ec238951a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVAL_LENGTH = 10  # number of seconds of the interval\n",
    "\n",
    "time = for_eye[\"timeStampDataPointEnd\"].values\n",
    "start_idxi = [0] + [idx+1 for idx, (t1, t2) in enumerate(zip(time[:-1], time[1:])) if t2 - t1 > INTERVAL_LENGTH]\n",
    "starti = [time[idx] for idx in start_idx]\n",
    "end_idxi = [idx for idx in start_idx[:-1]]\n",
    "endi = [time[idx-1] for idx in end_idx] + [time[-1]]\n",
    "#int_data = {\n",
    "   ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2b790-32cf-47ba-9c9d-b3a55a49e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871304de-7442-412a-9476-a0da726bf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(starti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd893659-5a32-449a-86ba-dececb4bc475",
   "metadata": {},
   "outputs": [],
   "source": [
    "end[-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc2a66-b15e-4657-b0da-957393419ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "endi[-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24f042-654e-4c90-85a0-af61d8c65ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240fa5b-1a28-45e1-96ac-4008e998e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diff\"] = df[\"value\"].rolling(window=2).apply(lambda x: x[1] - x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7224d8-e9d8-4f7c-89c9-136c644e4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_gaze_inplane1[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46782d-09d7-4d18-a74a-8e0972dbcff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_hpoo1 = np.linalg.norm(np.array(subj) - np.array(hpoo), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee648ef-b6dd-4b1a-bff3-b17f0b6318a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_hpoo1[658]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af290a-4943-40ac-89a4-66fbd1d54d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_hpoo[658]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46deef42-1b96-4baf-b59c-e9c449629142",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = [np.dot(v_gaze_vec_i, gaze_vec_i) for v_gaze_vec_i, gaze_vec_i in zip(v_gaze_vec, gaze_vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a97f5c7-a27a-47a8-b06c-19ede7725ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2[656]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85c370-8bea-4a24-b3fe-5fe1617e8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1[656]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328f7c6-c88d-4868-9f70-adab388881be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye[\"hitPointOnObject_x\"].diff().tolist()[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad6544-9e1d-4f00-be37-6f38cf616c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.subtract(hpoo, subj))[142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dadc2a4-29dd-424e-ace0-32cea9171af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_vec[142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991c561-b682-4a30-b7c5-72e63e8f47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hpoo = list(zip(for_eye[\"hitPointOnObject_x\"], for_eye[\"hitPointOnObject_y\"],for_eye[\"hitPointOnObject_z\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236da093-50cd-4b65-98d3-3393e556407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_vX[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94febc2-e82e-40da-806b-bb387ead7e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c92e5-e40a-4974-9f5d-6899cf93a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Volumes/SSD/6258_PointingTask_Randomization_1666084297.70049.json\"\n",
    "with open(path, 'r') as file:\n",
    "        # make json files parsable\n",
    "        data = \"[\" + file.read()\n",
    "        data = data[:len(data)-1] + \"]\"\n",
    "\n",
    "        # read data per file\n",
    "        subjectdf = pd.read_json(data)\n",
    "\n",
    "        # insert participant id in every line\n",
    "        subjectdf.insert(0, \"SubjectID\", [int(path[13:17])] * subjectdf.shape[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb9371-03d6-4034-9e2b-d8cb970923c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f77bb-38d7-439f-97f9-1c0095146ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "StartingPoints = pd.DataFrame(subjectdf.explode('PointingTaskStartingLocations'))\n",
    "StartingPoints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7cc88-de7b-4608-80b6-7004e8897aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "StartingPointsnorm = pd.json_normalize(subjectdf[\"InitialOrientation\"]).add_prefix(\"InitialOrientation_\")\n",
    "StartingPointsnorm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995e0f3-fa8f-46e0-84fd-5cd9d842681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 4 -n 1000 StartingPoints = pd.DataFrame(subjectdf.explode('PointingTaskStartingLocations'))\n",
    "%timeit -r 4 -n 1000 StartingPointsnorm = pd.json_normalize(subjectdf[\"InitialOrientation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d88187-1836-4889-a8a1-39fd1d2c4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectdf[\"PointingTaskRandomised\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898ab04-ccde-48b1-81f5-6d7e9a0bfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = pd.json_normalize(subjectdf[\"PointingTaskRandomised\"][0])\n",
    "normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0dc4e6-cea9-4afc-8cbe-de8dff26a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final = pd.DataFrame(normalized.explode('TargetLocationsRandom'))\n",
    "Final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dde911-aef4-42c2-9be1-c6f1b30219c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b651fc0-508d-44a6-83cc-5d3e862e67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize(subjectdf.PointingTaskStartingLocations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd427164-6297-4d35-8437-0a253dc5b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248886c8-6ceb-4598-9cd2-cc91edd206dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c114bf7-4054-4027-b09f-478fec8d1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 4 -n 1000\n",
    "StartingPointsnorm = pd.json_normalize(subjectdf[\"InitialOrientation\"]).add_suffix('_InitialOrientation')\n",
    "StartingPointsnorm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c044ce-d250-4ca1-834f-d4863fc257a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
