{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71bfb75a-c476-434a-8bf4-9d69cd4feada",
   "metadata": {},
   "source": [
    "# Calculate angles and velocities "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4edac8-e22a-4062-86eb-3a4fa091d456",
   "metadata": {},
   "source": [
    "Eucledian_distance.rename(columns={\"Continuous_Time\": \"time\", \n",
    "                                   \"eyePositionCombinedWorld.x\": \"xcoord_orig\", \n",
    "                                   \"eyePositionCombinedWorld.z\": \"zcoord_orig\", \n",
    "                                   \"eyePositionCombinedWorld.y\": \"ycoord_orig\", \n",
    "                                   \"hitPointOnObject_x\": \"xhpoo\", \n",
    "                                   \"hitPointOnObject_y\": \"yhpoo\", \n",
    "                                   \"hitPointOnObject_z\": \"zhpoo\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21b5102-f4de-4903-9fdd-cba54e1cc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math \n",
    "from collections import Counter \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a86316a-ac82-44fe-9b0b-25f70a8f829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the collider names are too detailed, here we create a dictionary with patterns to classify them into our categories of interest\n",
    "patterns = {'\\d{2}_Sa':'Passive_Agent', '\\d{2}_Cma':'Active_Agent', 'Building_\\d+': 'Building'}\n",
    "patterns.update(dict.fromkeys(['Castle-TaskBuilding_56','HighSilo-TaskBuilding_49', 'Windmill-TaskBuilding_10_1', 'Church_TaskBuilding_16'], 'Global_Landmark'))\n",
    "patterns.update(dict.fromkeys(['TaskBuilding_2','TaskBuilding_3', 'TaskBuilding_5', 'TaskBuilding_8', 'TaskBuilding_9', 'TaskBuilding_11', 'TaskBuilding_13', 'TaskBuilding_14', 'TaskBuilding_20', 'TaskBuilding_21', 'TaskBuilding_23','TaskBuilding_27', 'TaskBuilding_29', 'TaskBuilding_32', 'TaskBuilding_34',  'TaskBuilding_38', 'TaskBuilding_41', 'TaskBuilding_42', 'TaskBuilding_44', 'TaskBuilding_45', 'TaskBuilding_47', 'TaskBuilding_50', 'TaskBuilding_51', 'TaskBuilding_52', 'BasketballCourt_58', 'Construction_57', 'Graffity_02', 'Graffity_03', 'Graffity_05', 'Graffity_08', 'Graffity_09', 'Graffity_11', 'Graffity_13', 'Graffity_14', 'Graffity_20', 'Graffity_21', 'Graffity_23', 'Graffity_27', 'Graffity_29', 'Graffity_32', 'Graffity_34', 'Graffity_38', 'Graffity_41', 'Graffity_42', 'Graffity_44', 'Graffity_45', 'Graffity_47',  'Graffity_50', 'Graffity_51', 'Graffity_52'], 'TaskBuilding_Public'))\n",
    "patterns.update(dict.fromkeys(['TaskBuilding_1','TaskBuilding_4', 'TaskBuilding_6', 'TaskBuilding_7', 'TaskBuilding_12', 'TaskBuilding_15', 'TaskBuilding_17', 'TaskBuilding_18', 'TaskBuilding_19', 'TaskBuilding_22', 'TaskBuilding_24','TaskBuilding_25', 'TaskBuilding_26', 'TaskBuilding_28', 'TaskBuilding_30',  'TaskBuilding_31', 'TaskBuilding_33', 'TaskBuilding_35', 'TaskBuilding_36', 'TaskBuilding_37', 'TaskBuilding_39', 'TaskBuilding_40', 'TaskBuilding_43', 'TaskBuilding_48', 'TaskBuilding_54','TaskBuilding_55','Graffity_1','Graffity_4', 'Graffity_6', 'Graffity_7', 'Graffity_12', 'Graffity_15', 'Graffity_17', 'Graffity_18', 'Graffity_19', 'Graffity_22', 'Graffity_24','Graffity_25', 'Graffity_26', 'Graffity_28', 'Graffity_30',  'Graffity_31', 'Graffity_33', 'Graffity_35', 'Graffity_36', 'Graffity_37', 'Graffity_39', 'Graffity_40', 'Graffity_43', 'Graffity_48', 'Graffity_54', 'Graffity_55' ], 'TaskBuilding_Residential'))\n",
    "default_val = 'Background'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b57a0a6-5fb4-468c-ab0a-5f6e29a5ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: calculate MAD saccade\n",
    "def at_mad(angular_vel, th_0=200):\n",
    "    # defines the saccade threshold (code from Ashima)\n",
    "    threshs = []\n",
    "    while True:\n",
    "        # take th_0\n",
    "        threshs.append(th_0)\n",
    "        # get all angles smaller than this\n",
    "        angular_vel = angular_vel[angular_vel < th_0]\n",
    "\n",
    "        # MAD:\n",
    "        # take the median of all angles smaller than th_0\n",
    "        median = np.median(angular_vel)\n",
    "        # substract the median value\n",
    "        diff = np.sqrt((angular_vel - median) ** 2)\n",
    "        # get the median of these values\n",
    "        med_abs_deviation = np.median(diff)\n",
    "\n",
    "        # calcualte the next threshold with the median\n",
    "        # 1.486 used when assuming a normal distribution\n",
    "        th_1 = median + 3 * 1.486 * med_abs_deviation\n",
    "        # if the thresholds are too different, redo the while loop\n",
    "        if abs(th_0 - th_1) > 1:\n",
    "            th_0 = th_1\n",
    "        # else, set the final threshold to the current one, break the while loop and return values\n",
    "        else:\n",
    "            saccade_thresh = th_1\n",
    "            threshs.append(saccade_thresh)\n",
    "            break\n",
    "    return saccade_thresh, threshs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e0ead-c2fe-4a73-9f80-2e2f0e8c0824",
   "metadata": {},
   "source": [
    "# Starts Here\n",
    "Continuos colliders method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf604b8-e5bc-433b-be11-810494d17a22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0479_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0479_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0479_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:466: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(dist[index.index(start_idx) :])\n",
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:466: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(dist[index.index(start_idx) :])\n",
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:466: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(dist[index.index(start_idx) :])\n",
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2361_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2693_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2693_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2693_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2693_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2693_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3246_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3246_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3246_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3246_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3310_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3310_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3310_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3310_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3310_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-535225a1d365>:532: RuntimeWarning: Mean of empty slice\n",
      "  hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
      "<ipython-input-4-535225a1d365>:537: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3572_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-535225a1d365>\", line 190, in <module>\n",
      "    curr_line = for_eye.loc[idx]\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 895, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1124, in _getitem_axis\n",
      "    return self._get_label(key, axis=axis)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1073, in _get_label\n",
      "    return self.obj.xs(label, axis=axis)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3727, in xs\n",
      "    index = self.index\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1078, in format_exception_as_a_whole\n",
      "    head = self.prepare_header(etype, self.long_header)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1030, in prepare_header\n",
      "    colorsnormal = colors.Normal  # used a lot\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/utils/ipstruct.py\", line 146, in __getattr__\n",
      "    try:\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3454, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2076, in showtraceback\n",
      "    print('\\n' + self.get_exception_only(), file=sys.stderr)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2021, in get_exception_only\n",
      "    msg = traceback.format_exception_only(etype, value)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/traceback.py\", line 140, in format_exception_only\n",
      "    return list(TracebackException(etype, value, None).format_exception_only())\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/traceback.py\", line 523, in __init__\n",
      "    self._load_lines()\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/traceback.py\", line 535, in _load_lines\n",
      "    self.__context__._load_lines()\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/traceback.py\", line 533, in _load_lines\n",
      "    frame.line\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/traceback.py\", line 288, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/linecache.py\", line 16, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/linecache.py\", line 95, in updatecache\n",
      "    stat = os.stat(fullname)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/inspect.py\", line 1508, in getinnerframes\n",
      "    def getinnerframes(tb, context=1):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1079, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1115, in get_records\n",
      "    inspect_error()\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 152, in inspect_error\n",
      "    error('Internal Python error in the inspect module.\\n'\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/logging/__init__.py\", line 2045, in error\n",
      "    root.error(msg, *args, **kwargs)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/logging/__init__.py\", line 1471, in error\n",
      "    self._log(ERROR, msg, args, **kwargs)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/logging/__init__.py\", line 1585, in _log\n",
      "    self.handle(record)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/logging/__init__.py\", line 1595, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/logging/__init__.py\", line 1657, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/logging/__init__.py\", line 950, in handle\n",
      "    self.emit(record)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/logging/__init__.py\", line 1084, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/ipykernel/iostream.py\", line 404, in write\n",
      "    self.pub_thread.schedule(lambda : self._buffer.write(string))\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    self._event_pipe.send(b'')\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/zmq/sugar/socket.py\", line 491, in send\n",
      "    return super(Socket, self).send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 720, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 767, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 242, in zmq.backend.cython.socket._send_copy\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3376, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2076, in showtraceback\n",
      "    print('\\n' + self.get_exception_only(), file=sys.stderr)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2021, in get_exception_only\n",
      "    msg = traceback.format_exception_only(etype, value)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/traceback.py\", line 140, in format_exception_only\n",
      "    return list(TracebackException(etype, value, None).format_exception_only())\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/traceback.py\", line 523, in __init__\n",
      "    self._load_lines()\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/traceback.py\", line 535, in _load_lines\n",
      "    self.__context__._load_lines()\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/traceback.py\", line 533, in _load_lines\n",
      "    frame.line\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/traceback.py\", line 288, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/linecache.py\", line 16, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/linecache.py\", line 95, in updatecache\n",
      "    stat = os.stat(fullname)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "path = \"/Volumes/SSD/00_Data_Processing/Pre_processed/04_Interpolated\" \n",
    "\n",
    "# csv files in the path\n",
    "files = glob.glob(path + \"/*.csv\")\n",
    "  \n",
    "# defining an empty list to store \n",
    "# content\n",
    "data_frame = pd.DataFrame()\n",
    "content = []\n",
    "  \n",
    "# checking all the csv files in the \n",
    "# specified path\n",
    "for filename in files:\n",
    "    One_participant = pd.read_csv(filename)\n",
    "    # Here we identify the shifts on collider name\n",
    "    One_participant['Collider_shift'] = One_participant['Interpolated_collider'].shift(1) != One_participant['Interpolated_collider']\n",
    "    # Create calculate a cumulative sum of the collider changes\n",
    "    One_participant['counter'] = (One_participant['Collider_shift'] == True).cumsum()\n",
    "    # Shift the counter column by one row to align it with the correct row\n",
    "    One_participant['counter'] = One_participant['counter'].shift(1).fillna(0)\n",
    "    One_participantC = One_participant.copy()\n",
    "    #Create subset that only has the rows with shifts in colliders \n",
    "    One_participant_true = One_participant[One_participant['Collider_shift'] == True].reset_index().copy()\n",
    "    # Since shift converts index into float we change it back into int so that it can be read as index\n",
    "    One_participant_true[\"index_shift\"] = One_participant_true[\"index\"].shift(-1).astype('Int64')\n",
    "    # Calculate the difference in time between each shift\n",
    "    One_participant_true[\"Time_diff\"] = One_participant_true.timeStampDataPointEnd.diff(1).shift(-1)\n",
    "    One_participant_true.dropna(inplace=True)\n",
    "    #### Create the gaze column \n",
    "    One_participant[\"Time_of_Gaze\"] = np.nan\n",
    "    low = One_participant_true[\"index\"].to_list()\n",
    "    up = One_participant_true[\"index_shift\"].to_list()\n",
    "    time =  One_participant_true[\"Time_diff\"].to_list()\n",
    "    ranges = list(zip(low, up))\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        One_participant.loc[lower:upper,\"Time_of_Gaze\"]  = time[i]\n",
    "    One_participant[\"Gaze\"] = np.where(One_participant[\"Time_of_Gaze\"] > .250, \"Gaze\", \"Movement\")\n",
    "    One_participant_true[\"Gaze\"] = np.where(One_participant_true[\"Time_diff\"] > .250, \"Gaze\", \"Movement\")\n",
    "    low = []\n",
    "    up = []\n",
    "    \n",
    "    ######## Debbies Algorithm ########\n",
    "    \n",
    "    for_eye = One_participant.copy()\n",
    "    time = for_eye[\"timeStampDataPointEnd\"].tolist()\n",
    "    \n",
    "    ## Calculate Angular velocities\n",
    "    # get individual coordinates\n",
    "    subj = list(zip( for_eye[\"eyePositionCombinedWorld.x\"],for_eye[\"eyePositionCombinedWorld.y\"],for_eye[\"eyePositionCombinedWorld.z\"]))\n",
    "    hpoo = list(zip(for_eye[\"hitPointOnObject_x\"], for_eye[\"hitPointOnObject_y\"],for_eye[\"hitPointOnObject_z\"]))\n",
    "    # v_gaze_vec: get difference in hpoo\n",
    "    v_gaze_vec = list(zip(for_eye[\"hitPointOnObject_x\"].diff(), for_eye[\"hitPointOnObject_y\"].diff(),for_eye[\"hitPointOnObject_z\"].diff()))\n",
    "    # get difference in time:\n",
    "    ts = for_eye[\"timeStampDataPointEnd\"].diff().tolist()\n",
    "    # gaze_vec(t) is a unit vector in the direction of the gaze (eye+head) in world coordinates\n",
    "    g_vec = list(np.subtract(hpoo, subj))\n",
    "    gaze_vec = [np.array(v) / np.linalg.norm(np.array(v)) for v in g_vec]\n",
    "    # v_gaze_inplane: is a scalar indicating the velocity in world coordinates at the location that is gazed at orthogonal to the gaze axis.\n",
    "    z1 = [np.dot(v_gaze_vec_i, gaze_vec_i) for v_gaze_vec_i, gaze_vec_i in zip(v_gaze_vec, gaze_vec)]\n",
    "    # z = (<v_gaze_vec(t), gaze_vec(t)> * gaze_vec(t))\n",
    "    z = [z1[element] * np.array(gaze_vec[element]) for element in range(len(z1))]\n",
    "    # ||v_gaze_vec(t) - z||\n",
    "    v_gaze_inplane = np.linalg.norm(np.array(v_gaze_vec) - z, axis=-1)\n",
    "    #Eucledian distance between eye coordinates and hit on object\n",
    "    sub_hpoo = np.linalg.norm(np.array(subj) - np.array(hpoo), axis=-1)\n",
    "    # arctan2(v_gaze_inplane, sub_hpoo)\n",
    "    w_gaze = np.arctan2(v_gaze_inplane, sub_hpoo).tolist()\n",
    "    # Turn angle of radians into degrees over seconds \n",
    "    w_gaze = [(w / ts[idx] * 180 / math.pi) for idx, w in enumerate(w_gaze)]\n",
    "    # save df\n",
    "    for_eye[\"combined_vel\"] = w_gaze\n",
    "   \n",
    "    ### 10 second for threshold calculation starts here\n",
    "    \n",
    "    int_len = 10  # number of seconds of the interval\n",
    "    time = for_eye[\"timeStampDataPointEnd\"].values\n",
    "    start = [time[0]]\n",
    "    end = []\n",
    "    start_idx = [0]\n",
    "    end_idx = []\n",
    "    for t, ti in enumerate(time[1:], start=1):\n",
    "        if ti - start[-1] > int_len:\n",
    "            end.append(time[t - 1])\n",
    "            end_idx.append(t - 1)\n",
    "            start.append(ti)\n",
    "            start_idx.append(t)\n",
    "    # add the last timepoint to end\n",
    "    end.append(time[-1])\n",
    "    end_idx.append(len(time))\n",
    "\n",
    "    # save it as new df\n",
    "    int_data = pd.DataFrame({\n",
    "        \"start\": start,\n",
    "        \"end\": end,\n",
    "        \"start_idx\": start_idx,\n",
    "        \"end_idx\": end_idx\n",
    "    })\n",
    "    \n",
    "    combined_vel = for_eye[\"combined_vel\"]\n",
    "\n",
    "    # to add the final thresholds to for each segement\n",
    "    scct = []\n",
    "    for s, srt in enumerate(int_data[\"start\"].tolist()):\n",
    "        # get the slice of the combined velocity\n",
    "        angular_vel = combined_vel[start_idx[s] : end_idx[s]]\n",
    "        # use the at_mad function to caluclate the threshold\n",
    "        saccade_th, thres = at_mad(angular_vel)\n",
    "        if np.isnan(saccade_th):\n",
    "            scct.append(thres[0])\n",
    "        else:\n",
    "            # add it to scct\n",
    "            scct.append(saccade_th)\n",
    "\n",
    "    # add it to int_data and save\n",
    "    int_data[\"thresh\"] = scct\n",
    "    thr = int_data[\"thresh\"]\n",
    "\n",
    "    # go through all time intervals\n",
    "    thresh = [0.0] * len(time)\n",
    "    \n",
    "    for s, srt in enumerate(int_data[\"start\"].tolist()):\n",
    "        # repeat the threshold as often as the time interval is long\n",
    "        thresh = (\n",
    "            thresh[: start_idx[s]]\n",
    "            + [thr[s]] * len(time[start_idx[s] : end_idx[s]])\n",
    "            + thresh[end_idx[s]:]\n",
    "        )\n",
    "\n",
    "    # add the two lists (ht & et) to for_eye df\n",
    "    for_eye[\"thresh\"] = thresh\n",
    "\n",
    "    # eye-tracking\n",
    "    thres = int_data[\"thresh\"].values\n",
    "    combined_vel = for_eye[\"combined_vel\"].values\n",
    "\n",
    "    # define list where the fixations will be added too\n",
    "    is_fix = [np.nan] * len(combined_vel)\n",
    "    \n",
    "    start = int_data[\"start_idx\"].tolist()\n",
    "    end = int_data[\"end_idx\"].tolist()\n",
    "\n",
    "    # eye-tracking\n",
    "    thres = int_data[\"thresh\"].tolist()\n",
    "    combined_vel = for_eye[\"combined_vel\"].tolist()\n",
    "\n",
    "\n",
    "    for i in range(len(start)):\n",
    "        av = combined_vel[start[i] : end[i]]\n",
    "        # go through combined velocity and save all that are bigger than the threshold\n",
    "        fix = [ti if ti < thres[i] else np.nan for ti in av]\n",
    "        is_fix[start[i] : end[i]] = fix\n",
    "    for_eye[\"isFix\"] = is_fix\n",
    "\n",
    "    # save data\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    \n",
    "    #Everywhere  where there is Nans that is a saccade meaning this are the cells that are really fast \n",
    "    for_eye.reset_index(inplace=True)\n",
    "    \n",
    "    min_sacc_dur = 0.02  # min sacc duration\n",
    "    min_gaze_dur = 0.04  # min gaze duration (Ashima uses 0.05)\n",
    "\n",
    "    time = for_eye.timeStampDataPointEnd.tolist()\n",
    "    index = for_eye.index.tolist()  # index of df for easier use\n",
    "\n",
    "    start_time = time[0]  # update for each change\n",
    "    start_idx = index[0]  # will be updated each event and used to add to the lists\n",
    "\n",
    "    # to save:\n",
    "    isFix = []\n",
    "    combined_vel = []\n",
    "\n",
    "    # if the first sample does not have any data\n",
    "    if math.isnan(for_eye.iloc[0][\"combined_vel\"]) and not math.isnan(\n",
    "        for_eye.iloc[1][\"combined_vel\"]\n",
    "    ):\n",
    "        start_time = time[1]   # update for each change\n",
    "        start_idx = index[1]  # will be updated each event and used to add to the lists\n",
    "        isFix = [np.nan]\n",
    "        combined_vel = [np.nan]\n",
    "\n",
    "    # starting with a sacc\n",
    "    if math.isnan(for_eye.loc[start_idx][\"isFix\"]):\n",
    "        event = 0  # == sacc\n",
    "    # starting with a gaze\n",
    "    else:\n",
    "        event = 1  # == gaze\n",
    "\n",
    "    # go through the list:\n",
    "    for idx in index[index.index(start_idx) : -1]:\n",
    "        curr_line = for_eye.loc[idx]\n",
    "        next_line = for_eye.loc[idx+1]\n",
    "\n",
    "        # gaze (--> sacc): now gaze, next one is sacc\n",
    "        if not math.isnan(curr_line.isFix) and math.isnan(next_line.isFix):\n",
    "            # if the event is too small but we are currently in a big gaze, keep isFix change combined_vel\n",
    "            if event == 1 and next_line.timeStampDataPointEnd - start_time < min_gaze_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = combined_vel + [np.nan] * (\n",
    "                    idx + 1 - start_idx\n",
    "                )  # change combined_vel\n",
    "            # elif current event to small and we are in big saccade, change isFix, change combined_vel\n",
    "            elif event == 0 and next_line.timeStampDataPointEnd - start_time < min_gaze_dur:\n",
    "                isFix = isFix + [np.nan] * (idx + 1 - start_idx)\n",
    "                combined_vel = combined_vel + [np.nan] * (idx + 1 - start_idx)\n",
    "            # elif current event big enough, keep isFix and keep combined_vel and change event to 1,update length\n",
    "            elif next_line.timeStampDataPointEnd - start_time >= min_gaze_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = (\n",
    "                    combined_vel\n",
    "                    + for_eye.loc[\n",
    "                        start_idx:idx, \"combined_vel\"\n",
    "                    ].values.tolist()\n",
    "                )  # keep combined_vel\n",
    "                event = 1  # change events\n",
    "            # update start_time and start_idx\n",
    "            start_idx = idx + 1\n",
    "            start_time = for_eye.loc[idx + 1][\"timeStampDataPointEnd\"]\n",
    "\n",
    "        # sacc (--> gaze): now sacc, next one is gaze\n",
    "        elif math.isnan(curr_line.isFix) and not math.isnan(next_line.isFix):\n",
    "            # if the event is too small and we are currently in a big sacc, keep isFix change combined_vel\n",
    "            if event == 0 and next_line.timeStampDataPointEnd - start_time < min_sacc_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = combined_vel + [np.nan] * (\n",
    "                    idx + 1 - start_idx\n",
    "                )  # change combined_vel\n",
    "            # elif current event to small but we are in big gaze, change isFix, change combined_vel\n",
    "            elif event == 1 and next_line.timeStampDataPointEnd - start_time < min_sacc_dur:\n",
    "                isFix = (\n",
    "                    isFix\n",
    "                    + for_eye.loc[\n",
    "                        start_idx:idx, \"combined_vel\"\n",
    "                    ].values.tolist()\n",
    "                )  # change isFix\n",
    "                combined_vel = combined_vel + [np.nan] * (\n",
    "                    idx + 1 - start_idx\n",
    "                )  # change combined_vel\n",
    "            # elif current event big enough, keep isFix and keep combined_vel and change event to 0,update length\n",
    "            elif next_line.timeStampDataPointEnd - start_time >= min_sacc_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = (\n",
    "                    combined_vel\n",
    "                    + for_eye.loc[\n",
    "                        start_idx:idx, \"combined_vel\"\n",
    "                    ].values.tolist()\n",
    "                )  # keep combined_vel\n",
    "                event = 0  # change events\n",
    "            # update start_time and start_idx\n",
    "            start_idx = idx + 1\n",
    "            start_time = for_eye.loc[idx + 1][\"timeStampDataPointEnd\"]\n",
    "\n",
    "        # last index:\n",
    "        if idx + 1 == index[-1]:\n",
    "            # gaze:\n",
    "            if not math.isnan(next_line.isFix):\n",
    "                # if the event is too small but we are currently in a big gaze, keep isFix change combined_vel\n",
    "                if (\n",
    "                    event == 1\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_gaze_dur\n",
    "                ):\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )  # change combined_vel\n",
    "                # elif current event to small and we are in big saccade, change isFix, change combined_vel\n",
    "                elif (\n",
    "                    event == 0\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_gaze_dur\n",
    "                ):\n",
    "                    isFix = isFix + [np.nan] * (idx + 2 - start_idx)\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )\n",
    "                # elif current event big enough, keep isFix and keep combined_vel and change event to 1,update length\n",
    "                elif next_line.timeStampDataPointEnd + 0.011 - start_time >= min_gaze_dur:\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = (\n",
    "                        combined_vel\n",
    "                        + for_eye.loc[\n",
    "                            start_idx:, \"combined_vel\"\n",
    "                        ].values.tolist()\n",
    "                    )  # keep combined_vel\n",
    "            # sacc:\n",
    "            elif math.isnan(next_line.isFix):\n",
    "                # if the event is too small and we are currently in a big sacc, keep isFix change combined_vel\n",
    "                if (\n",
    "                    event == 0\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_sacc_dur\n",
    "                ):\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )  # change combined_vel\n",
    "                # elif current event to small but we are in big gaze, change isFix, change combined_vel\n",
    "                elif (\n",
    "                    event == 1\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_sacc_dur\n",
    "                ):\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[\n",
    "                            start_idx:, \"combined_vel\"\n",
    "                        ].values.tolist()\n",
    "                    )  # change isFix\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )  # change combined_vel\n",
    "                # elif current event big enough, keep isFix and keep combined_vel and change event to 0,update length\n",
    "                elif next_line.timeStampDataPointEnd + 0.011 - start_time >= min_sacc_dur:\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = (\n",
    "                        combined_vel\n",
    "                        + for_eye.loc[\n",
    "                            start_idx:, \"combined_vel\"\n",
    "                        ].values.tolist()\n",
    "                    )  # keep combined_vel\n",
    "\n",
    "    # save everything:\n",
    "    for_eye[\"isFix\"] = isFix\n",
    "    for_eye[\"corrected_vel\"] = combined_vel\n",
    "    # save data\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    \n",
    "    time = for_eye.timeStampDataPointEnd.tolist()\n",
    "    \n",
    "    ########## EVENTS, LENGTH, AVG DISTANCE, NAME OF OBJECT ##########\n",
    "    index = for_eye.index.tolist()  # index of df for easier use\n",
    "\n",
    "    events = [np.nan] * len(\n",
    "        for_eye\n",
    "    )  # sacc begin == 1, sacc end == -1; gaze begin == 2, gaze end == -2\n",
    "\n",
    "    # if the first sample does not have any data\n",
    "    if math.isnan(for_eye.iloc[0][\"combined_vel\"]) and not math.isnan(\n",
    "        for_eye.iloc[1][\"combined_vel\"]\n",
    "    ):\n",
    "        start_idx = index[\n",
    "            1\n",
    "        ]  # will be updated each event and used to add to the lists\n",
    "        events[1] = 2\n",
    "        length = [np.nan]\n",
    "        dist = [\n",
    "            np.nan\n",
    "        ]  # to save the distance to the hitpoint at each timestamps\n",
    "        avg_dist = [\n",
    "            np.nan\n",
    "        ]  # to save the average distance of collider(s) during event\n",
    "        names = [np.nan]  # to save the name of the current gaze\n",
    "    else:\n",
    "        start_idx = index[\n",
    "            0\n",
    "        ]  # will be updated each event and used to add to the lists\n",
    "        length = []\n",
    "        dist = []  # to save the distance to the hitpoint at each timestamps\n",
    "        avg_dist = (\n",
    "            []\n",
    "        )  # to save the average distance of collider(s) during event\n",
    "        names = []  # to save the name of the current gaze\n",
    "        if math.isnan(for_eye.iloc[index[0]][\"combined_vel\"]):\n",
    "            events[0] = 1\n",
    "        else:\n",
    "            events[0] = 2\n",
    "\n",
    "    start_time = for_eye.loc[start_idx][\"timeStampDataPointEnd\"].tolist()\n",
    "    # go through the list:\n",
    "    for idx in index[index.index(start_idx) : -1]:\n",
    "        curr_line = for_eye.loc[idx]\n",
    "        next_line = for_eye.loc[idx + 1]\n",
    "\n",
    "        # distance:\n",
    "        hpoo = np.array(\n",
    "            [curr_line.hitPointOnObject_x, curr_line.hitPointOnObject_y, curr_line.hitPointOnObject_z]\n",
    "        )  # hitpoints on object\n",
    "        coord_orig = np.array(\n",
    "            [\n",
    "                curr_line[\"eyePositionCombinedWorld.x\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.y\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.z\"],\n",
    "            ]\n",
    "        )  # position of eyes\n",
    "        dist = dist + [\n",
    "            np.linalg.norm(hpoo - coord_orig)\n",
    "        ]  # calculate to distance at this timpoint\n",
    "\n",
    "        # gaze --> sacc: now gaze, next one is sacc\n",
    "        if not math.isnan(curr_line.isFix) and math.isnan(next_line.isFix):\n",
    "            # get name:\n",
    "            res = dict(\n",
    "                Counter(for_eye.loc[start_idx:idx, \"Interpolated_collider\"].values.tolist())\n",
    "            )\n",
    "            names = names + [\n",
    "                max(res.keys(), key=(lambda new_k: res[new_k]))\n",
    "            ] * (idx + 1 - start_idx)\n",
    "            # length, distance, events\n",
    "            length = length + [curr_line.timeStampDataPointEnd - start_time] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # length of event\n",
    "            avg_dist = avg_dist + [\n",
    "                np.nanmean(dist[index.index(start_idx) :])\n",
    "            ] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # average distance to collider(s) during event\n",
    "            events[index.index(idx)] = -2  # end of gaze\n",
    "            events[index.index(idx) + 1] = 1  # beginning of sacc\n",
    "            # new idx\n",
    "            start_time = curr_line.timeStampDataPointEnd\n",
    "            start_idx = idx + 1\n",
    "\n",
    "        # sacc --> gaze: now sacc, next one is gaze\n",
    "        elif math.isnan(curr_line.isFix) and not math.isnan(next_line.isFix):\n",
    "            # get name:\n",
    "            res = dict(\n",
    "                Counter(for_eye.loc[start_idx:idx, \"Interpolated_collider\"].values.tolist())\n",
    "            )\n",
    "            names = names + [\n",
    "                max(res.keys(), key=(lambda new_k: res[new_k]))\n",
    "            ] * (idx + 1 - start_idx)\n",
    "            # length, distance, events\n",
    "            length = length + [curr_line.timeStampDataPointEnd - start_time] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # length of event\n",
    "            avg_dist = avg_dist + [\n",
    "                np.nanmean(dist[index.index(start_idx) :])\n",
    "            ] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # average distance to collider(s) during event\n",
    "            events[index.index(idx)] = -1  # end of sacc\n",
    "            events[index.index(idx) + 1] = 2  # beginning of gaze\n",
    "            # new idx\n",
    "            start_time = curr_line.timeStampDataPointEnd\n",
    "            start_idx = idx + 1\n",
    "\n",
    "        # last index:\n",
    "        if idx + 1 == index[-1]:\n",
    "            # gaze:\n",
    "            if not math.isnan(next_line.isFix):\n",
    "                events[-1] = -2  # end of gaze\n",
    "            # sacc:\n",
    "            elif math.isnan(next_line.isFix):\n",
    "                events[-1] = -1  # end of sacc\n",
    "            length = length + [next_line.timeStampDataPointEnd - start_time] * (\n",
    "                idx + 2 - start_idx\n",
    "            )  # length of event\n",
    "            # distance\n",
    "            avg_dist = avg_dist + [\n",
    "                np.nanmean(dist[index.index(start_idx) :])\n",
    "            ] * (\n",
    "                idx + 2 - start_idx\n",
    "            )  # average distance to collider(s) during event\n",
    "            hpoo = np.array(\n",
    "                [curr_line.hitPointOnObject_x, curr_line.hitPointOnObject_y, curr_line.hitPointOnObject_z]\n",
    "            )  # hitpoints on object\n",
    "            coord_orig = np.array(\n",
    "                [\n",
    "                    curr_line[\"eyePositionCombinedWorld.x\"],\n",
    "                    curr_line[\"eyePositionCombinedWorld.y\"],\n",
    "                    curr_line[\"eyePositionCombinedWorld.z\"],\n",
    "                ]\n",
    "            )  # position of eyes\n",
    "            dist = dist + [\n",
    "                np.linalg.norm(hpoo - coord_orig)\n",
    "            ]  # calculate to distance at this timpoint\n",
    "            # names\n",
    "            res = dict(\n",
    "                Counter(for_eye.loc[start_idx:, \"Interpolated_collider\"].values.tolist())\n",
    "            )\n",
    "            names = names + [\n",
    "                max(res.keys(), key=(lambda new_k: res[new_k]))\n",
    "            ] * (idx + 2 - start_idx)\n",
    "    # save everything:\n",
    "    for_eye[\"events\"] = events\n",
    "    for_eye[\"length\"] = length\n",
    "    for_eye[\"distance\"] = dist\n",
    "    for_eye[\"avg_dist\"] = avg_dist\n",
    "    for_eye[\"names\"] = names\n",
    "    # display(for_eye[['time','isFix','events','hon_all','names']])\n",
    "    # save data\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    # Change average distance to correct for the potential of other events \n",
    "    # so distance and avg_dist\n",
    "\n",
    "    # total lists:\n",
    "    all_dist = []\n",
    "    avg_dist = []\n",
    "\n",
    "    # updated after each gaze\n",
    "    dist = []\n",
    "    hon_pos = []\n",
    "    dur_gaze = False\n",
    "\n",
    "    # during event:\n",
    "    # go through the list:      \n",
    "    for g,gz in enumerate(for_eye['events']):\n",
    "        curr_line = for_eye.loc[g]\n",
    "        if gz == 2.0 or gz == 1.0:\n",
    "            dur_gaze = True\n",
    "            # get the gazed at object\n",
    "            curr_gaze = curr_line.names\n",
    "        # if you are currently in a gaze:\n",
    "        if dur_gaze:\n",
    "            # if you are currently having the correct element, add the position\n",
    "            if curr_line.Interpolated_collider == curr_gaze:    \n",
    "                hon_pos = hon_pos + [[curr_line.hitPointOnObject_x,\n",
    "                    curr_line.hitPointOnObject_y,\n",
    "                    curr_line.hitPointOnObject_z,]]\n",
    "            dist = dist + [np.array([curr_line[\"eyePositionCombinedWorld.x\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.y\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.z\"],])]\n",
    "\n",
    "        # once the gaze is over, take the avg_dist\n",
    "        if gz == -2.0 or gz == -1.0:\n",
    "            hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
    "            # calculate to distance at this timpoint\n",
    "            dist = [np.linalg.norm(hon_pos[c] - dist[c]) for c in range(len(dist))]\n",
    "            all_dist = all_dist + dist\n",
    "            # average distance during the gaze event\n",
    "            avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n",
    "\n",
    "            # reset everything:\n",
    "            dist = []\n",
    "            hon_pos = []\n",
    "            dur_gaze = False\n",
    "\n",
    "        # if there are parts that are neither gaze nor saccade:\n",
    "        if (not dur_gaze) and (gz not in [2.0,1.0]) and (len(all_dist) + len(dist) != g + 1):\n",
    "            all_dist = all_dist + [np.nan]\n",
    "            avg_dist = avg_dist + [np.nan]\n",
    "\n",
    "        if len(all_dist) + len(dist) != g + 1:\n",
    "            display(g)\n",
    "\n",
    "    if dur_gaze:\n",
    "        hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
    "        # calculate to distance at this timpoint\n",
    "        dist = [np.linalg.norm(hon_pos[c] - dist[c]) for c in range(len(dist))]\n",
    "        all_dist = all_dist + dist\n",
    "        # average distance during the gaze event\n",
    "        avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n",
    "\n",
    "    # add them to for_eye\n",
    "    for_eye['distance'] = all_dist\n",
    "    for_eye['avg_dist'] = avg_dist\n",
    "    \n",
    "    for_eye[\"names\"] =  for_eye.names.fillna(method='ffill').fillna(method='bfill')\n",
    "    for_eye['Collider_CategoricalN'] = for_eye['names'].apply(lambda x: next((val for key, val in patterns.items() if re.match(key, x)), default_val))\n",
    "    \n",
    "\n",
    "    # save data\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    \n",
    "    # Define the condition and the string to add\n",
    "    Mask_1f = ((for_eye['Collider_CategoricalN'] == \"Active_Agent\") & (for_eye['Face_Hits'] == \"Face\")) | ((for_eye['Collider_CategoricalN'] == \"Passive_Agent\") & (for_eye['Face_Hits'] == \"Face\"))\n",
    "    Mask_2f  = ((for_eye['Collider_Categorical'] == \"Active_Agent\") | (for_eye['Collider_Categorical'] == \"Passive_Agent\")) & (for_eye['Face_Hits'] == \"Face\")    \n",
    "    string_to_add = \"_Face\"\n",
    "    # Use the loc method to index the rows where the condition is met\n",
    "    for_eye.loc[Mask_1f, 'Collider_CategoricalN'] = for_eye.loc[Mask_1f, 'Collider_CategoricalN'] + string_to_add\n",
    "    for_eye.loc[Mask_2f, 'Collider_Categorical'] = for_eye.loc[Mask_2f, 'Collider_Categorical'] + string_to_add\n",
    "    for_eye.to_csv(f\"/Volumes/SSD/00_Data_Processing/Pre_processed/05_Debbies_gaze/{filename[-10:-4]}.csv\", index=True)\n",
    "    print(filename[-10:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d61f8d-93e3-4f8e-9aed-434130b15800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-5e621d054a72>\", line 14, in <module>\n",
      "    One_participant = pd.read_csv(filename)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 610, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 468, in _read\n",
      "    return parser.read(nrows)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 1057, in read\n",
      "    index, columns, col_dict = self._engine.read(nrows)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 2061, in read\n",
      "    data = self._reader.read(nrows)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 756, in pandas._libs.parsers.TextReader.read\n",
      "  File \"pandas/_libs/parsers.pyx\", line 771, in pandas._libs.parsers.TextReader._read_low_memory\n",
      "  File \"pandas/_libs/parsers.pyx\", line 827, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 814, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 1951, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ParserError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/tracysanchezpacheco/opt/anaconda3/lib/python3.8/inspect.py\", line 745, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5e621d054a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mOne_participant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Here we identify the shifts on collider name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ParserError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "path = \"/Volumes/SSD/00_Data_Processing/Pre_processed/04_Interpolated\" \n",
    "\n",
    "# csv files in the path\n",
    "files = glob.glob(path + \"/*.csv\")\n",
    "  \n",
    "# defining an empty list to store \n",
    "# content\n",
    "data_frame = pd.DataFrame()\n",
    "content = []\n",
    "  \n",
    "# checking all the csv files in the \n",
    "# specified path\n",
    "for filename in files:\n",
    "    One_participant = pd.read_csv(filename)\n",
    "    # Here we identify the shifts on collider name\n",
    "    One_participant['Collider_shift'] = One_participant['Interpolated_collider'].shift(1) != One_participant['Interpolated_collider']\n",
    "    # Create calculate a cumulative sum of the collider changes\n",
    "    One_participant['counter'] = (One_participant['Collider_shift'] == True).cumsum()\n",
    "    # Shift the counter column by one row to align it with the correct row\n",
    "    One_participant['counter'] = One_participant['counter'].shift(1).fillna(0)\n",
    "    One_participantC = One_participant.copy()\n",
    "    #Create subset that only has the rows with shifts in colliders \n",
    "    One_participant_true = One_participant[One_participant['Collider_shift'] == True].reset_index().copy()\n",
    "    # Since shift converts index into float we change it back into int so that it can be read as index\n",
    "    One_participant_true[\"index_shift\"] = One_participant_true[\"index\"].shift(-1).astype('Int64')\n",
    "    # Calculate the difference in time between each shift\n",
    "    One_participant_true[\"Time_diff\"] = One_participant_true.timeStampDataPointEnd.diff(1).shift(-1)\n",
    "    One_participant_true.dropna(inplace=True)\n",
    "    #### Create the gaze column \n",
    "    One_participant[\"Time_of_Gaze\"] = np.nan\n",
    "    low = One_participant_true[\"index\"].to_list()\n",
    "    up = One_participant_true[\"index_shift\"].to_list()\n",
    "    time =  One_participant_true[\"Time_diff\"].to_list()\n",
    "    ranges = list(zip(low, up))\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        One_participant.loc[lower:upper,\"Time_of_Gaze\"]  = time[i]\n",
    "    One_participant[\"Gaze\"] = np.where(One_participant[\"Time_of_Gaze\"] > .250, \"Gaze\", \"Movement\")\n",
    "    One_participant_true[\"Gaze\"] = np.where(One_participant_true[\"Time_diff\"] > .250, \"Gaze\", \"Movement\")\n",
    "    low = []\n",
    "    up = []\n",
    "    \n",
    "    ######## Debbies Algorithm ########\n",
    "    \n",
    "    for_eye = One_participant.copy()\n",
    "   \n",
    "    time = for_eye[\"timeStampDataPointEnd\"].tolist()\n",
    "    # get individual coordinates\n",
    "    subj = list(zip( for_eye[\"eyePositionCombinedWorld.x\"],for_eye[\"eyePositionCombinedWorld.y\"],for_eye[\"eyePositionCombinedWorld.z\"]))\n",
    "    hpoo = list(zip(for_eye[\"hitPointOnObject_x\"], for_eye[\"hitPointOnObject_y\"],for_eye[\"hitPointOnObject_z\"]))\n",
    "\n",
    "    # v_gaze_vec: get difference in hpoo\n",
    "    v_vX = for_eye[\"hitPointOnObject_x\"].diff().tolist()\n",
    "    v_vY = for_eye[\"hitPointOnObject_y\"].diff().tolist()\n",
    "    v_vZ = for_eye[\"hitPointOnObject_z\"].diff().tolist()\n",
    "    \n",
    "\n",
    "    # get difference in time:\n",
    "    ts = pd.DataFrame(time).apply(lambda x: x.diff())[0].tolist()\n",
    "    v_gaze_vec = list(zip(v_vX, v_vY, v_vZ))\n",
    "\n",
    "    # gaze_vec(t) is a unit vector in the direction of the gaze (eye+head) in world coordinates\n",
    "    g_vec = list(np.subtract(hpoo, subj))\n",
    "    gaze_vec = [np.array(v) / np.linalg.norm(np.array(v)) for v in g_vec]\n",
    "   \n",
    "\n",
    "    # v_gaze_inplane: is a scalar indicating the velocity in world coordinates at the location that is gazed at orthogonal to the gaze axis.\n",
    "    # v_gaze_inplane(t) = ||v_gaze_vec(t) - (<v_gaze_vec(t), gaze_vec(t)> * gaze_vec(t))||:\n",
    "    # z1 = (<v_gaze_vec(t), gaze_vec(t)>)\n",
    "    z1 = [np.array(v_gaze_vec[t]).dot(np.array(gaze_vec[t]))\n",
    "            for t in range(len(v_vX))]\n",
    "\n",
    "    # z = (<v_gaze_vec(t), gaze_vec(t)> * gaze_vec(t))\n",
    "    z = [z1[t] * np.array(gaze_vec[t]) for t in range(len(v_vX))]\n",
    "\n",
    "    # ||v_gaze_vec(t) - z||\n",
    "    v_gaze_inplane = [np.linalg.norm((np.array(v_gaze_vec[t]) - z[t]).tolist())\n",
    "            for t in range(len(v_gaze_vec))\n",
    "                     ]\n",
    "    # w_gaze(t) = arctan2(||subject_vec(t) - hpoo_vec(t)||, v_gaze_inplane)\n",
    "\n",
    "    # sub_hpoo = ||subject_vec(t) - hpoo_vec(t)||\n",
    "    sub_hpoo = [np.linalg.norm(np.array(subj[t]) - np.array(hpoo[t]))\n",
    "            for t in range(len(hpoo))]\n",
    "\n",
    "    # arctan2(v_gaze_inplane, sub_hpoo)\n",
    "    w_gaze = np.arctan2(v_gaze_inplane, sub_hpoo).tolist()\n",
    "\n",
    "    # turn angle of radians into degrees\n",
    "    #w_gaze = [np.rad2deg(value) for value in w_gaze]\n",
    "    w_gaze = [(w / ts[idx] * 180 / math.pi) for idx, w in enumerate(w_gaze)]\n",
    "    # save df\n",
    "    for_eye[\"combined_vel\"] = w_gaze\n",
    "   ### 10 second starts here \n",
    "    int_len = 10  # number of seconds of the interval\n",
    "\n",
    "    time = for_eye[\"timeStampDataPointEnd\"].tolist()\n",
    "    start = []\n",
    "    end = []\n",
    "    start_idx = []\n",
    "    end_idx = []\n",
    "    for t, ti in enumerate(time):\n",
    "        if ti == time[0]:\n",
    "            start.append(ti)\n",
    "            start_idx.append(t)\n",
    "        if ti - start[-1] > int_len:\n",
    "            # if the current timepoint is more than int_len away from start, set it to new start\n",
    "            start.append(ti)\n",
    "            start_idx.append(t)\n",
    "            # and set end to the timepoint before that\n",
    "            end.append(time[t - 1])\n",
    "            end_idx.append(t - 1)\n",
    "    # add the last timepoint to end\n",
    "    # (there is a very slim chance that the last start and end are the same timepoint --> might cause errors)\n",
    "    end.append(time[-1])\n",
    "    end_idx.append(len(time))\n",
    "\n",
    "    # save it as new df\n",
    "    int_data = list(zip(start, end, start_idx, end_idx))\n",
    "    int_data = pd.DataFrame(\n",
    "        int_data, columns=[\"start\", \"end\", \"start_idx\", \"end_idx\"]\n",
    "    )\n",
    "\n",
    "    combined_vel = for_eye[\"combined_vel\"]\n",
    "\n",
    "    # to shorten the slicing in the next for loop\n",
    "    start_idx = int_data[\"start_idx\"].tolist()\n",
    "    end_idx = int_data[\"end_idx\"].tolist()\n",
    "\n",
    "    # to add the final thresholds to for each segement\n",
    "    scct = []\n",
    "    for s, srt in enumerate(int_data[\"start\"].tolist()):\n",
    "        # get the slice of the combined velocity\n",
    "        angular_vel = combined_vel[start_idx[s] : end_idx[s]]\n",
    "        # use the at_mad function to caluclate the threshold\n",
    "        saccade_th, thres = at_mad(angular_vel)\n",
    "        if np.isnan(saccade_th):\n",
    "            scct.append(thres[0])\n",
    "        else:\n",
    "            # add it to scct\n",
    "            scct.append(saccade_th)\n",
    "\n",
    "    # add it to int_data and save\n",
    "    int_data[\"thresh\"] = scct\n",
    "    int_data = pd.DataFrame(int_data)\n",
    "    time = for_eye.timeStampDataPointEnd.tolist()\n",
    "    start_idx = int_data[\"start_idx\"].tolist()\n",
    "    end_idx = int_data[\"end_idx\"].tolist()\n",
    "    thr = int_data[\"thresh\"].tolist()\n",
    "\n",
    "    # go through all time intervals\n",
    "    thresh = [0.0] * len(time)\n",
    "    for s, srt in enumerate(int_data[\"start\"].tolist()):\n",
    "        # repeat the threshold as often as the time interval is long\n",
    "        thresh = (\n",
    "            thresh[: start_idx[s]]\n",
    "            + [thr[s]] * len(time[start_idx[s] : end_idx[s]])\n",
    "            + thresh[end_idx[s]:]\n",
    "        )\n",
    "\n",
    "    # add the two lists (ht & et) to for_eye df\n",
    "    for_eye[\"thresh\"] = thresh\n",
    "\n",
    "    # save for_eye df\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    \n",
    "    start = int_data[\"start_idx\"].tolist()\n",
    "    end = int_data[\"end_idx\"].tolist()\n",
    "\n",
    "    # eye-tracking\n",
    "    thres = int_data[\"thresh\"].tolist()\n",
    "    combined_vel = for_eye[\"combined_vel\"].tolist()\n",
    "\n",
    "    # define list where the fixations will be added too\n",
    "    is_fix = [np.nan] * len(combined_vel)\n",
    "\n",
    "    for i in range(len(start)):\n",
    "        av = combined_vel[start[i] : end[i]]\n",
    "        # go through combined velocity and save all that are bigger than the threshold\n",
    "        fix = [ti if ti < thres[i] else np.nan for ti in av]\n",
    "        is_fix[start[i] : end[i]] = fix\n",
    "\n",
    "    # save\n",
    "    for_eye[\"isFix\"] = is_fix\n",
    "\n",
    "    # save data\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    #Everywhere  where there is Nans that is a saccade meaning this are the cells that are really fast \n",
    "    \n",
    "    for_eye.reset_index(inplace=True)\n",
    "    \n",
    "    min_sacc_dur = 0.02  # min sacc duration\n",
    "    min_gaze_dur = 0.04  # min gaze duration (Ashima uses 0.05)\n",
    "\n",
    "    time = for_eye.timeStampDataPointEnd.tolist()\n",
    "    index = for_eye.index.tolist()  # index of df for easier use\n",
    "\n",
    "    start_time = time[0]  # update for each change\n",
    "    start_idx = index[0]  # will be updated each event and used to add to the lists\n",
    "\n",
    "    # to save:\n",
    "    isFix = []\n",
    "    combined_vel = []\n",
    "\n",
    "    # if the first sample does not have any data\n",
    "    if math.isnan(for_eye.iloc[0][\"combined_vel\"]) and not math.isnan(\n",
    "        for_eye.iloc[1][\"combined_vel\"]\n",
    "    ):\n",
    "        start_time = time[1]   # update for each change\n",
    "        start_idx = index[1]  # will be updated each event and used to add to the lists\n",
    "        isFix = [np.nan]\n",
    "        combined_vel = [np.nan]\n",
    "\n",
    "    # starting with a sacc\n",
    "    if math.isnan(for_eye.loc[start_idx][\"isFix\"]):\n",
    "        event = 0  # == sacc\n",
    "    # starting with a gaze\n",
    "    else:\n",
    "        event = 1  # == gaze\n",
    "\n",
    "    # go through the list:\n",
    "    for idx in index[index.index(start_idx) : -1]:\n",
    "        curr_line = for_eye.loc[idx]\n",
    "        next_line = for_eye.loc[idx+1]\n",
    "\n",
    "        # gaze (--> sacc): now gaze, next one is sacc\n",
    "        if not math.isnan(curr_line.isFix) and math.isnan(next_line.isFix):\n",
    "            # if the event is too small but we are currently in a big gaze, keep isFix change combined_vel\n",
    "            if event == 1 and next_line.timeStampDataPointEnd - start_time < min_gaze_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = combined_vel + [np.nan] * (\n",
    "                    idx + 1 - start_idx\n",
    "                )  # change combined_vel\n",
    "            # elif current event to small and we are in big saccade, change isFix, change combined_vel\n",
    "            elif event == 0 and next_line.timeStampDataPointEnd - start_time < min_gaze_dur:\n",
    "                isFix = isFix + [np.nan] * (idx + 1 - start_idx)\n",
    "                combined_vel = combined_vel + [np.nan] * (idx + 1 - start_idx)\n",
    "            # elif current event big enough, keep isFix and keep combined_vel and change event to 1,update length\n",
    "            elif next_line.timeStampDataPointEnd - start_time >= min_gaze_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = (\n",
    "                    combined_vel\n",
    "                    + for_eye.loc[\n",
    "                        start_idx:idx, \"combined_vel\"\n",
    "                    ].values.tolist()\n",
    "                )  # keep combined_vel\n",
    "                event = 1  # change events\n",
    "            # update start_time and start_idx\n",
    "            start_idx = idx + 1\n",
    "            start_time = for_eye.loc[idx + 1][\"timeStampDataPointEnd\"]\n",
    "\n",
    "        # sacc (--> gaze): now sacc, next one is gaze\n",
    "        elif math.isnan(curr_line.isFix) and not math.isnan(next_line.isFix):\n",
    "            # if the event is too small and we are currently in a big sacc, keep isFix change combined_vel\n",
    "            if event == 0 and next_line.timeStampDataPointEnd - start_time < min_sacc_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = combined_vel + [np.nan] * (\n",
    "                    idx + 1 - start_idx\n",
    "                )  # change combined_vel\n",
    "            # elif current event to small but we are in big gaze, change isFix, change combined_vel\n",
    "            elif event == 1 and next_line.timeStampDataPointEnd - start_time < min_sacc_dur:\n",
    "                isFix = (\n",
    "                    isFix\n",
    "                    + for_eye.loc[\n",
    "                        start_idx:idx, \"combined_vel\"\n",
    "                    ].values.tolist()\n",
    "                )  # change isFix\n",
    "                combined_vel = combined_vel + [np.nan] * (\n",
    "                    idx + 1 - start_idx\n",
    "                )  # change combined_vel\n",
    "            # elif current event big enough, keep isFix and keep combined_vel and change event to 0,update length\n",
    "            elif next_line.timeStampDataPointEnd - start_time >= min_sacc_dur:\n",
    "                isFix = (\n",
    "                    isFix + for_eye.loc[start_idx:idx, \"isFix\"].values.tolist()\n",
    "                )  # keep isFix\n",
    "                combined_vel = (\n",
    "                    combined_vel\n",
    "                    + for_eye.loc[\n",
    "                        start_idx:idx, \"combined_vel\"\n",
    "                    ].values.tolist()\n",
    "                )  # keep combined_vel\n",
    "                event = 0  # change events\n",
    "            # update start_time and start_idx\n",
    "            start_idx = idx + 1\n",
    "            start_time = for_eye.loc[idx + 1][\"timeStampDataPointEnd\"]\n",
    "\n",
    "        # last index:\n",
    "        if idx + 1 == index[-1]:\n",
    "            # gaze:\n",
    "            if not math.isnan(next_line.isFix):\n",
    "                # if the event is too small but we are currently in a big gaze, keep isFix change combined_vel\n",
    "                if (\n",
    "                    event == 1\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_gaze_dur\n",
    "                ):\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )  # change combined_vel\n",
    "                # elif current event to small and we are in big saccade, change isFix, change combined_vel\n",
    "                elif (\n",
    "                    event == 0\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_gaze_dur\n",
    "                ):\n",
    "                    isFix = isFix + [np.nan] * (idx + 2 - start_idx)\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )\n",
    "                # elif current event big enough, keep isFix and keep combined_vel and change event to 1,update length\n",
    "                elif next_line.timeStampDataPointEnd + 0.011 - start_time >= min_gaze_dur:\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = (\n",
    "                        combined_vel\n",
    "                        + for_eye.loc[\n",
    "                            start_idx:, \"combined_vel\"\n",
    "                        ].values.tolist()\n",
    "                    )  # keep combined_vel\n",
    "            # sacc:\n",
    "            elif math.isnan(next_line.isFix):\n",
    "                # if the event is too small and we are currently in a big sacc, keep isFix change combined_vel\n",
    "                if (\n",
    "                    event == 0\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_sacc_dur\n",
    "                ):\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )  # change combined_vel\n",
    "                # elif current event to small but we are in big gaze, change isFix, change combined_vel\n",
    "                elif (\n",
    "                    event == 1\n",
    "                    and next_line.timeStampDataPointEnd + 0.011 - start_time < min_sacc_dur\n",
    "                ):\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[\n",
    "                            start_idx:, \"combined_vel\"\n",
    "                        ].values.tolist()\n",
    "                    )  # change isFix\n",
    "                    combined_vel = combined_vel + [np.nan] * (\n",
    "                        idx + 2 - start_idx\n",
    "                    )  # change combined_vel\n",
    "                # elif current event big enough, keep isFix and keep combined_vel and change event to 0,update length\n",
    "                elif next_line.timeStampDataPointEnd + 0.011 - start_time >= min_sacc_dur:\n",
    "                    isFix = (\n",
    "                        isFix\n",
    "                        + for_eye.loc[start_idx:, \"isFix\"].values.tolist()\n",
    "                    )  # keep isFix\n",
    "                    combined_vel = (\n",
    "                        combined_vel\n",
    "                        + for_eye.loc[\n",
    "                            start_idx:, \"combined_vel\"\n",
    "                        ].values.tolist()\n",
    "                    )  # keep combined_vel\n",
    "\n",
    "    # save everything:\n",
    "    for_eye[\"isFix\"] = isFix\n",
    "    for_eye[\"corrected_vel\"] = combined_vel\n",
    "    # save data\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    \n",
    "    time = for_eye.timeStampDataPointEnd.tolist()\n",
    "    \n",
    "    ########## EVENTS, LENGTH, AVG DISTANCE, NAME OF OBJECT ##########\n",
    "    index = for_eye.index.tolist()  # index of df for easier use\n",
    "\n",
    "    events = [np.nan] * len(\n",
    "        for_eye\n",
    "    )  # sacc begin == 1, sacc end == -1; gaze begin == 2, gaze end == -2\n",
    "\n",
    "    # if the first sample does not have any data\n",
    "    if math.isnan(for_eye.iloc[0][\"combined_vel\"]) and not math.isnan(\n",
    "        for_eye.iloc[1][\"combined_vel\"]\n",
    "    ):\n",
    "        start_idx = index[\n",
    "            1\n",
    "        ]  # will be updated each event and used to add to the lists\n",
    "        events[1] = 2\n",
    "        length = [np.nan]\n",
    "        dist = [\n",
    "            np.nan\n",
    "        ]  # to save the distance to the hitpoint at each timestamps\n",
    "        avg_dist = [\n",
    "            np.nan\n",
    "        ]  # to save the average distance of collider(s) during event\n",
    "        names = [np.nan]  # to save the name of the current gaze\n",
    "    else:\n",
    "        start_idx = index[\n",
    "            0\n",
    "        ]  # will be updated each event and used to add to the lists\n",
    "        length = []\n",
    "        dist = []  # to save the distance to the hitpoint at each timestamps\n",
    "        avg_dist = (\n",
    "            []\n",
    "        )  # to save the average distance of collider(s) during event\n",
    "        names = []  # to save the name of the current gaze\n",
    "        if math.isnan(for_eye.iloc[index[0]][\"combined_vel\"]):\n",
    "            events[0] = 1\n",
    "        else:\n",
    "            events[0] = 2\n",
    "\n",
    "    start_time = for_eye.loc[start_idx][\"timeStampDataPointEnd\"].tolist()\n",
    "    # go through the list:\n",
    "    for idx in index[index.index(start_idx) : -1]:\n",
    "        curr_line = for_eye.loc[idx]\n",
    "        next_line = for_eye.loc[idx + 1]\n",
    "\n",
    "        # distance:\n",
    "        hpoo = np.array(\n",
    "            [curr_line.hitPointOnObject_x, curr_line.hitPointOnObject_y, curr_line.hitPointOnObject_z]\n",
    "        )  # hitpoints on object\n",
    "        coord_orig = np.array(\n",
    "            [\n",
    "                curr_line[\"eyePositionCombinedWorld.x\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.y\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.z\"],\n",
    "            ]\n",
    "        )  # position of eyes\n",
    "        dist = dist + [\n",
    "            np.linalg.norm(hpoo - coord_orig)\n",
    "        ]  # calculate to distance at this timpoint\n",
    "\n",
    "        # gaze --> sacc: now gaze, next one is sacc\n",
    "        if not math.isnan(curr_line.isFix) and math.isnan(next_line.isFix):\n",
    "            # get name:\n",
    "            res = dict(\n",
    "                Counter(for_eye.loc[start_idx:idx, \"Interpolated_collider\"].values.tolist())\n",
    "            )\n",
    "            names = names + [\n",
    "                max(res.keys(), key=(lambda new_k: res[new_k]))\n",
    "            ] * (idx + 1 - start_idx)\n",
    "            # length, distance, events\n",
    "            length = length + [curr_line.timeStampDataPointEnd - start_time] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # length of event\n",
    "            avg_dist = avg_dist + [\n",
    "                np.nanmean(dist[index.index(start_idx) :])\n",
    "            ] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # average distance to collider(s) during event\n",
    "            events[index.index(idx)] = -2  # end of gaze\n",
    "            events[index.index(idx) + 1] = 1  # beginning of sacc\n",
    "            # new idx\n",
    "            start_time = curr_line.timeStampDataPointEnd\n",
    "            start_idx = idx + 1\n",
    "\n",
    "        # sacc --> gaze: now sacc, next one is gaze\n",
    "        elif math.isnan(curr_line.isFix) and not math.isnan(next_line.isFix):\n",
    "            # get name:\n",
    "            res = dict(\n",
    "                Counter(for_eye.loc[start_idx:idx, \"Interpolated_collider\"].values.tolist())\n",
    "            )\n",
    "            names = names + [\n",
    "                max(res.keys(), key=(lambda new_k: res[new_k]))\n",
    "            ] * (idx + 1 - start_idx)\n",
    "            # length, distance, events\n",
    "            length = length + [curr_line.timeStampDataPointEnd - start_time] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # length of event\n",
    "            avg_dist = avg_dist + [\n",
    "                np.nanmean(dist[index.index(start_idx) :])\n",
    "            ] * (\n",
    "                idx + 1 - start_idx\n",
    "            )  # average distance to collider(s) during event\n",
    "            events[index.index(idx)] = -1  # end of sacc\n",
    "            events[index.index(idx) + 1] = 2  # beginning of gaze\n",
    "            # new idx\n",
    "            start_time = curr_line.timeStampDataPointEnd\n",
    "            start_idx = idx + 1\n",
    "\n",
    "        # last index:\n",
    "        if idx + 1 == index[-1]:\n",
    "            # gaze:\n",
    "            if not math.isnan(next_line.isFix):\n",
    "                events[-1] = -2  # end of gaze\n",
    "            # sacc:\n",
    "            elif math.isnan(next_line.isFix):\n",
    "                events[-1] = -1  # end of sacc\n",
    "            length = length + [next_line.timeStampDataPointEnd - start_time] * (\n",
    "                idx + 2 - start_idx\n",
    "            )  # length of event\n",
    "            # distance\n",
    "            avg_dist = avg_dist + [\n",
    "                np.nanmean(dist[index.index(start_idx) :])\n",
    "            ] * (\n",
    "                idx + 2 - start_idx\n",
    "            )  # average distance to collider(s) during event\n",
    "            hpoo = np.array(\n",
    "                [curr_line.hitPointOnObject_x, curr_line.hitPointOnObject_y, curr_line.hitPointOnObject_z]\n",
    "            )  # hitpoints on object\n",
    "            coord_orig = np.array(\n",
    "                [\n",
    "                    curr_line[\"eyePositionCombinedWorld.x\"],\n",
    "                    curr_line[\"eyePositionCombinedWorld.y\"],\n",
    "                    curr_line[\"eyePositionCombinedWorld.z\"],\n",
    "                ]\n",
    "            )  # position of eyes\n",
    "            dist = dist + [\n",
    "                np.linalg.norm(hpoo - coord_orig)\n",
    "            ]  # calculate to distance at this timpoint\n",
    "            # names\n",
    "            res = dict(\n",
    "                Counter(for_eye.loc[start_idx:, \"Interpolated_collider\"].values.tolist())\n",
    "            )\n",
    "            names = names + [\n",
    "                max(res.keys(), key=(lambda new_k: res[new_k]))\n",
    "            ] * (idx + 2 - start_idx)\n",
    "    # save everything:\n",
    "    for_eye[\"events\"] = events\n",
    "    for_eye[\"length\"] = length\n",
    "    for_eye[\"distance\"] = dist\n",
    "    for_eye[\"avg_dist\"] = avg_dist\n",
    "    for_eye[\"names\"] = names\n",
    "    # display(for_eye[['time','isFix','events','hon_all','names']])\n",
    "    # save data\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    # Change average distance to correct for the potential of other events \n",
    "    # so distance and avg_dist\n",
    "\n",
    "    # total lists:\n",
    "    all_dist = []\n",
    "    avg_dist = []\n",
    "\n",
    "    # updated after each gaze\n",
    "    dist = []\n",
    "    hon_pos = []\n",
    "    dur_gaze = False\n",
    "\n",
    "    # during event:\n",
    "    # go through the list:      \n",
    "    for g,gz in enumerate(for_eye['events']):\n",
    "        curr_line = for_eye.loc[g]\n",
    "        if gz == 2.0 or gz == 1.0:\n",
    "            dur_gaze = True\n",
    "            # get the gazed at object\n",
    "            curr_gaze = curr_line.names\n",
    "        # if you are currently in a gaze:\n",
    "        if dur_gaze:\n",
    "            # if you are currently having the correct element, add the position\n",
    "            if curr_line.Interpolated_collider == curr_gaze:    \n",
    "                hon_pos = hon_pos + [[curr_line.hitPointOnObject_x,\n",
    "                    curr_line.hitPointOnObject_y,\n",
    "                    curr_line.hitPointOnObject_z,]]\n",
    "            dist = dist + [np.array([curr_line[\"eyePositionCombinedWorld.x\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.y\"],\n",
    "                curr_line[\"eyePositionCombinedWorld.z\"],])]\n",
    "\n",
    "        # once the gaze is over, take the avg_dist\n",
    "        if gz == -2.0 or gz == -1.0:\n",
    "            hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
    "            # calculate to distance at this timpoint\n",
    "            dist = [np.linalg.norm(hon_pos[c] - dist[c]) for c in range(len(dist))]\n",
    "            all_dist = all_dist + dist\n",
    "            # average distance during the gaze event\n",
    "            avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n",
    "\n",
    "            # reset everything:\n",
    "            dist = []\n",
    "            hon_pos = []\n",
    "            dur_gaze = False\n",
    "\n",
    "        # if there are parts that are neither gaze nor saccade:\n",
    "        if (not dur_gaze) and (gz not in [2.0,1.0]) and (len(all_dist) + len(dist) != g + 1):\n",
    "            all_dist = all_dist + [np.nan]\n",
    "            avg_dist = avg_dist + [np.nan]\n",
    "\n",
    "        if len(all_dist) + len(dist) != g + 1:\n",
    "            display(g)\n",
    "\n",
    "    if dur_gaze:\n",
    "        hon_pos = [np.nanmean(hon_pos, axis=0)] * len(dist)\n",
    "        # calculate to distance at this timpoint\n",
    "        dist = [np.linalg.norm(hon_pos[c] - dist[c]) for c in range(len(dist))]\n",
    "        all_dist = all_dist + dist\n",
    "        # average distance during the gaze event\n",
    "        avg_dist = avg_dist + [np.nanmean(dist)] * len(dist)\n",
    "\n",
    "    # add them to for_eye\n",
    "    for_eye['distance'] = all_dist\n",
    "    for_eye['avg_dist'] = avg_dist\n",
    "    \n",
    "    for_eye[\"names\"] =  for_eye.names.fillna(method='ffill').fillna(method='bfill')\n",
    "    for_eye['Collider_CategoricalN'] = for_eye['names'].apply(lambda x: next((val for key, val in patterns.items() if re.match(key, x)), default_val))\n",
    "    \n",
    "\n",
    "    for_eye = pd.DataFrame(for_eye)\n",
    "    \n",
    "    # Define the condition and the string to add\n",
    "    Mask_1f = ((for_eye['Collider_CategoricalN'] == \"Active_Agent\") & (for_eye['Face_Hits'] == \"Face\")) | ((for_eye['Collider_CategoricalN'] == \"Passive_Agent\") & (for_eye['Face_Hits'] == \"Face\"))\n",
    "    Mask_2f  = ((for_eye['Collider_Categorical'] == \"Active_Agent\") | (for_eye['Collider_Categorical'] == \"Passive_Agent\")) & (for_eye['Face_Hits'] == \"Face\")    \n",
    "    string_to_add = \"_Face\"\n",
    "    # Use the loc method to index the rows where the condition is met\n",
    "    for_eye.loc[Mask_1f, 'Collider_CategoricalN'] = for_eye.loc[Mask_1f, 'Collider_CategoricalN'] + string_to_add\n",
    "    for_eye.loc[Mask_2f, 'Collider_Categorical'] = for_eye.loc[Mask_2f, 'Collider_Categorical'] + string_to_add\n",
    "    for_eye.to_csv(f\"/Volumes/SSD/00_Data_Processing/Pre_processed/05_Debbies_gaze/{filename[-10:-4]}.csv\", index=True)\n",
    "    print(filename[-10:-4])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf5201-311f-4810-81b7-7f7f9d7ff986",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Volumes/SSD/00_Data_Processing/Pre_processed/04_Interpolated\" \n",
    "\n",
    "# csv files in the path\n",
    "files = glob.glob(path + \"/*.csv\")\n",
    "  \n",
    "# defining an empty list to store \n",
    "# content\n",
    "data_frame = pd.DataFrame()\n",
    "content = []\n",
    "  \n",
    "# checking all the csv files in the \n",
    "# specified path\n",
    "for filename in files:\n",
    "    One_participant = pd.read_csv(filename)\n",
    "    # Here we identify the shifts on collider name\n",
    "    One_participant['Collider_shift'] = One_participant['Interpolated_collider'].shift(1) != One_participant['Interpolated_collider']\n",
    "    # Create calculate a cumulative sum of the collider changes\n",
    "    One_participant['counter'] = (One_participant['Collider_shift'] == True).cumsum()\n",
    "    # Shift the counter column by one row to align it with the correct row\n",
    "    One_participant['counter'] = One_participant['counter'].shift(1).fillna(0)\n",
    "    One_participantC = One_participant.copy()\n",
    "    #Create subset that only has the rows with shifts in colliders \n",
    "    One_participant_true = One_participant[One_participant['Collider_shift'] == True].reset_index().copy()\n",
    "    # Since shift converts index into float we change it back into int so that it can be read as index\n",
    "    One_participant_true[\"index_shift\"] = One_participant_true[\"index\"].shift(-1).astype('Int64')\n",
    "    # Calculate the difference in time between each shift\n",
    "    One_participant_true[\"Time_diff\"] = One_participant_true.timeStampDataPointEnd.diff(1).shift(-1)\n",
    "    One_participant_true.dropna(inplace=True)\n",
    "    #### Create the gaze column \n",
    "    One_participant[\"Time_of_Gaze\"] = np.nan\n",
    "    low = One_participant_true[\"index\"].to_list()\n",
    "    up = One_participant_true[\"index_shift\"].to_list()\n",
    "    time =  One_participant_true[\"Time_diff\"].to_list()\n",
    "    ranges = list(zip(low, up))\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        One_participant.loc[lower:upper,\"Time_of_Gaze\"]  = time[i]\n",
    "    One_participant[\"Gaze\"] = np.where(One_participant[\"Time_of_Gaze\"] > .250, \"Gaze\", \"Movement\")\n",
    "    One_participant_true[\"Gaze\"] = np.where(One_participant_true[\"Time_diff\"] > .250, \"Gaze\", \"Movement\")\n",
    "    low = []\n",
    "    up = []\n",
    "    \n",
    "    ######## Debbies Algorithm ########\n",
    "    \n",
    "    for_eye = One_participant.copy()\n",
    "   \n",
    "    time = for_eye[\"timeStampDataPointEnd\"].tolist()\n",
    "    # get individual coordinates\n",
    "    subj = list(zip( for_eye[\"eyePositionCombinedWorld.x\"],for_eye[\"eyePositionCombinedWorld.y\"],for_eye[\"eyePositionCombinedWorld.z\"]))\n",
    "    hpoo = list(zip(for_eye[\"hitPointOnObject_x\"], for_eye[\"hitPointOnObject_y\"],for_eye[\"hitPointOnObject_z\"]))\n",
    "\n",
    "    # v_gaze_vec: get difference in hpoo\n",
    "    v_vX = for_eye[\"hitPointOnObject_x\"].diff().tolist()\n",
    "    v_vY = for_eye[\"hitPointOnObject_y\"].diff().tolist()\n",
    "    v_vZ = for_eye[\"hitPointOnObject_z\"].diff().tolist()\n",
    "    \n",
    "\n",
    "    # get difference in time:\n",
    "    ts = pd.DataFrame(time).apply(lambda x: x.diff())[0].tolist()\n",
    "    v_gaze_vec = list(zip(v_vX, v_vY, v_vZ))\n",
    "\n",
    "    # gaze_vec(t) is a unit vector in the direction of the gaze (eye+head) in world coordinates\n",
    "    g_vec = [np.array(hpoo[v] - np.array(subj[v])) for v in range(len(subj))]\n",
    "    gaze_vec = [np.array(v) / np.linalg.norm(np.array(v)) for v in g_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6450582-e43e-4834-9cf9-12f36aaba75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Remember the rolling window thing \n",
    "\n",
    "df[\"diff\"] = df[\"value\"].rolling(window=2).apply(lambda x: x[1] - x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9b047-5700-4f75-b0e2-29e9fb869910",
   "metadata": {},
   "source": [
    "# Debbies plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e93b3-918b-412a-94f9-40440dc22dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye = pd.read_csv(\"/Volumes/SSD/00_Data_Processing/Pre_processed/03_Debbies_gaze/One_participant_WDC.csv\", index_col=\"timeStampDataPointEnd\")\n",
    "\n",
    "window_lower = for_eye.index.tolist()[2070]\n",
    "window_upper = for_eye.index.tolist()[2270]\n",
    "\n",
    "titel = \"Hit Points of Gazes\"\n",
    "            \n",
    "\n",
    "# get time:\n",
    "ts = for_eye.index.tolist()  # to make it easier\n",
    "time = ts[\n",
    "    ts.index(\n",
    "        list(filter(lambda i: i > window_lower, ts))[0]\n",
    "    ) : ts.index(list(filter(lambda i: i < window_upper, ts))[-1])\n",
    "    + 1\n",
    "]  # get all timestamps in the important time window\n",
    "\n",
    "# get shorter df:\n",
    "for_eye = for_eye.iloc[ts.index(time[0]) : (ts.index(time[-1]) + 1)]\n",
    "\n",
    "\n",
    "# hon: for showing lines in plot\n",
    "hon = for_eye[\"Interpolated_collider\"].tolist()\n",
    "new_col = [\n",
    "    hon[n] if hon[n] != hon[n - 1] and not pd.isnull(hon[n]) else np.nan\n",
    "    for n in range(len(hon))\n",
    "]\n",
    "\n",
    "hon_ts = [\n",
    "    ti for cnt, ti in enumerate(time) if isinstance(new_col[cnt], str)\n",
    "]  # timestamps\n",
    "\n",
    "# get gazes:\n",
    "gaze = for_eye[~for_eye[\"isFix\"].isnull()]\n",
    "gaze = gaze.rename({'hitPointOnObject_x': 'xgaze', 'hitPointOnObject_y': 'ygaze', 'hitPointOnObject_z': 'zgaze'}, axis=1)\n",
    "\n",
    "sacc = for_eye[~for_eye.index.isin(gaze.index)]\n",
    "sacc = sacc.rename({'hitPointOnObject_x': 'xsacc', 'hitPointOnObject_y': 'ysacc', 'hitPointOnObject_z': 'zsacc'}, axis=1)\n",
    "\n",
    "\n",
    "# plot it:\n",
    "sns.set(rc={\"figure.figsize\": (17, 9)})\n",
    "sns.set_style(\n",
    "    \"white\"\n",
    ")  # styledict, or one of {darkgrid, whitegrid, dark, white, ticks}\n",
    "\n",
    "f, (axis) = plt.subplots(2, 1)\n",
    "\n",
    "\n",
    "for x, xc in enumerate(hon_ts):\n",
    "    if not np.isnan(xc):\n",
    "        axis[0].axvline(\n",
    "            x=xc, color=\"#987284\", alpha=0.2, label=\"_Hidden label\"\n",
    "        )\n",
    "\n",
    "color_gaze = {\n",
    "    \"xgaze\": \"#5FAD56\",\n",
    "    \"ygaze\": \"#27408B\",\n",
    "    \"zgaze\": \"#4C86A8\",\n",
    "}\n",
    "color_sacc = {\n",
    "    \"xsacc\": \"#BA1200\",\n",
    "    \"ysacc\": \"#CD96CD\",\n",
    "    \"zsacc\": \"#F0A202\",\n",
    "}\n",
    "\n",
    "gaze[[\"xgaze\", \"ygaze\", \"zgaze\"]].plot(\n",
    "    color=[\n",
    "        color_gaze.get(x, \"#333333\")\n",
    "        for x in gaze[[\"xgaze\", \"ygaze\", \"zgaze\"]]\n",
    "    ],\n",
    "    ax=axis[0],\n",
    "    marker=\"o\",\n",
    "    ls=\"\",\n",
    ")\n",
    "\n",
    "sacc[[\"xsacc\", \"ysacc\", \"zsacc\"]].plot(\n",
    "    color=[\n",
    "        color_sacc.get(x, \"#333333\")\n",
    "        for x in sacc[[\"xsacc\", \"ysacc\", \"zsacc\"]]\n",
    "    ],\n",
    "    ax=axis[0],\n",
    "    marker=\"o\",\n",
    "    ls=\"\",\n",
    ")\n",
    "\n",
    "axis[0].set_title(\n",
    "    titel,\n",
    "    fontsize=22,\n",
    "    fontweight='bold',\n",
    ")\n",
    "axis[0].legend(loc=\"upper right\", fontsize=18)\n",
    "axis[0].xaxis.label.set_visible(False)\n",
    "axis[0].set_ylabel(\"coordinates\", fontsize=20)\n",
    "axis[0].yaxis.set_tick_params(labelsize = 14) # change tick size\n",
    "axis[0].xaxis.set_tick_params(labelsize = 14) \n",
    "\n",
    "\n",
    "\n",
    "axis[1].plot(time, for_eye[\"combined_vel\"].tolist(), \"g\", label = \"combined_vel\")\n",
    "axis[1].plot(time, for_eye[\"thresh\"].tolist(), \"r\", label = \"threshold\")\n",
    "\n",
    "#axis[3].plot(time, long_events_mad, \"k\")\n",
    "## axis[2].plot(time, blinks, \"b\")  # blinks\n",
    "axis[1].set_ylim(0, 600)\n",
    "axis[1].set_title(\n",
    "        \"Velocities\",\n",
    "        fontsize=22,\n",
    "        fontweight='bold',\n",
    "    )\n",
    "axis[1].legend(loc=\"upper right\", fontsize=18)\n",
    "#plt.xticks(fontsize=14)\n",
    "#ax.set_xticklabels(time,fontsize=20)\n",
    "#plt.suptitle(uid, fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "axis[1].set_xlabel(\"time (sec)\", fontsize=20)\n",
    "axis[1].set_ylabel(\"veloctiy\", fontsize=20)\n",
    "axis[1].yaxis.set_tick_params(labelsize = 14) # change tick size\n",
    "axis[1].xaxis.set_tick_params(labelsize = 14) \n",
    "\n",
    "plt.suptitle(titel, fontsize=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378392c-2700-4f37-b716-a04d6c39e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_eye"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
